{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jupyter_contrib_nbextensions && jupyter contrib nbextension install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  음료수 캔 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# 키워드 입력\n",
    "keyword = \"음료수 캔\"\n",
    "key = \"soda can\"\n",
    "\n",
    "\n",
    "\n",
    "# 웹접속 - 네이버 이미지 접속\n",
    "# 79.0.3945.36 / chrome version\n",
    "print(\"접속중\")\n",
    "driver = webdriver.Chrome(executable_path=\"./chromedriver.exe\")\n",
    "driver.implicitly_wait(30)\n",
    "\n",
    "url = 'https://search.naver.com/search.naver?where=image&sm=tab_jum&query={}'.format(keyword)\n",
    "driver.get(url)\n",
    "# 페이지 스크롤 다운\n",
    "body = driver.find_element_by_css_selector('body')\n",
    "for i in range(60):\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)\n",
    "\n",
    "# 이미지 링크 수집\n",
    "imgs = driver.find_elements_by_css_selector('img._img')\n",
    "result = []\n",
    "for img in tqdm(imgs):\n",
    "    if 'http' in img.get_attribute('src'):\n",
    "        result.append(img.get_attribute('src'))\n",
    "# print(result)\n",
    "\n",
    "driver.close()\n",
    "print('수집완료')\n",
    "\n",
    "# 파일 저장\n",
    "import os\n",
    "if not os.path.isdir('./{}'.format(key)):\n",
    "    print('폴더생성')\n",
    "    os.mkdir('./{}'.format(key))\n",
    "\n",
    "# 다운로드\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "print(\"다운로드중\")\n",
    "for index, link in tqdm(enumerate(result)):\n",
    "    start = link.rfind('.')\n",
    "    end = link.rfind('&')\n",
    "    # print(link[start:end])\n",
    "    filetype = link[start:end]\n",
    "    if filetype == '.jpg':  # jpg 만 다운\n",
    "        urlretrieve(link, './{}/{}{}{}'.format(key, key, index, filetype))\n",
    "        time.sleep(1)\n",
    "print(\"다운로드 완료\")\n",
    "\n",
    "# import zipfile\n",
    "# zip_file = zipfile.Zipfile('./{}.zip'.format(keyword),'w')\n",
    "# # 이 폴더안에 파일 가져오는거\n",
    "# for image in tqdm(os.listdir('./{}'.format(keyword))):\n",
    "#     zip_file.write('./{}/{}'.format(keyword,image), compress_type=zip_file.ZIP_DEFLATED)\n",
    "# zip_file.close()\n",
    "# print(\"압축완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통조림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# 키워드 입력\n",
    "keyword = \"통조림 캔\"\n",
    "key = \"canned\"\n",
    "\n",
    "\n",
    "\n",
    "# 웹접속 - 네이버 이미지 접속\n",
    "# 79.0.3945.36 / chrome version\n",
    "print(\"접속중\")\n",
    "driver = webdriver.Chrome(executable_path=\"./chromedriver.exe\")\n",
    "driver.implicitly_wait(30)\n",
    "\n",
    "url = 'https://search.naver.com/search.naver?where=image&sm=tab_jum&query={}'.format(keyword)\n",
    "driver.get(url)\n",
    "# 페이지 스크롤 다운\n",
    "body = driver.find_element_by_css_selector('body')\n",
    "for i in range(60):\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)\n",
    "\n",
    "# 이미지 링크 수집\n",
    "imgs = driver.find_elements_by_css_selector('img._img')\n",
    "result = []\n",
    "for img in tqdm(imgs):\n",
    "    if 'http' in img.get_attribute('src'):\n",
    "        result.append(img.get_attribute('src'))\n",
    "# print(result)\n",
    "\n",
    "driver.close()\n",
    "print('수집완료')\n",
    "\n",
    "# 파일 저장\n",
    "import os\n",
    "if not os.path.isdir('./{}'.format(key)):\n",
    "    print('폴더생성')\n",
    "    os.mkdir('./{}'.format(key))\n",
    "\n",
    "# 다운로드\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "print(\"다운로드중\")\n",
    "for index, link in tqdm(enumerate(result)):\n",
    "    start = link.rfind('.')\n",
    "    end = link.rfind('&')\n",
    "    # print(link[start:end])\n",
    "    filetype = link[start:end]\n",
    "    if filetype == '.jpg':  # jpg 만 다운\n",
    "        urlretrieve(link, './{}/{}{}{}'.format(key, key, index, filetype))\n",
    "        time.sleep(1)\n",
    "print(\"다운로드 완료\")\n",
    "\n",
    "# import zipfile\n",
    "# zip_file = zipfile.Zipfile('./{}.zip'.format(keyword),'w')\n",
    "# # 이 폴더안에 파일 가져오는거\n",
    "# for image in tqdm(os.listdir('./{}'.format(keyword))):\n",
    "#     zip_file.write('./{}/{}'.format(keyword,image), compress_type=zip_file.ZIP_DEFLATED)\n",
    "# zip_file.close()\n",
    "# print(\"압축완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 캔맥주"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# 키워드 입력\n",
    "keyword = \"캔맥주\"\n",
    "key = \"beer\"\n",
    "\n",
    "\n",
    "\n",
    "# 웹접속 - 네이버 이미지 접속\n",
    "# 79.0.3945.36 / chrome version\n",
    "print(\"접속중\")\n",
    "driver = webdriver.Chrome(executable_path=\"./chromedriver.exe\")\n",
    "driver.implicitly_wait(30)\n",
    "\n",
    "url = 'https://search.naver.com/search.naver?where=image&sm=tab_jum&query={}'.format(keyword)\n",
    "driver.get(url)\n",
    "# 페이지 스크롤 다운\n",
    "body = driver.find_element_by_css_selector('body')\n",
    "for i in range(60):\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)\n",
    "\n",
    "# 이미지 링크 수집\n",
    "imgs = driver.find_elements_by_css_selector('img._img')\n",
    "result = []\n",
    "for img in tqdm(imgs):\n",
    "    if 'http' in img.get_attribute('src'):\n",
    "        result.append(img.get_attribute('src'))\n",
    "# print(result)\n",
    "\n",
    "driver.close()\n",
    "print('수집완료')\n",
    "\n",
    "# 파일 저장\n",
    "import os\n",
    "if not os.path.isdir('./{}'.format(key)):\n",
    "    print('폴더생성')\n",
    "    os.mkdir('./{}'.format(key))\n",
    "\n",
    "# 다운로드\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "print(\"다운로드중\")\n",
    "for index, link in tqdm(enumerate(result)):\n",
    "    start = link.rfind('.')\n",
    "    end = link.rfind('&')\n",
    "    # print(link[start:end])\n",
    "    filetype = link[start:end]\n",
    "    if filetype == '.jpg':  # jpg 만 다운\n",
    "        urlretrieve(link, './{}/{}{}{}'.format(key, key, index, filetype))\n",
    "        time.sleep(1)\n",
    "print(\"다운로드 완료\")\n",
    "\n",
    "# import zipfile\n",
    "# zip_file = zipfile.Zipfile('./{}.zip'.format(keyword),'w')\n",
    "# # 이 폴더안에 파일 가져오는거\n",
    "# for image in tqdm(os.listdir('./{}'.format(keyword))):\n",
    "#     zip_file.write('./{}/{}'.format(keyword,image), compress_type=zip_file.ZIP_DEFLATED)\n",
    "# zip_file.close()\n",
    "# print(\"압축완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 전처리\n",
    "#https://keraskorea.github.io/posts/2018-10-24-little_data_powerful_model/\n",
    "\n",
    "- 데이터 전처리와 Augmentation\n",
    "    - 모델이 적은 이미지에서 최대한 많은 정보를 뽑아내서 학습할 수 있도록 우선 이미지를 augment 시켜보도록 하겠습니다. 이미지를 사용할 때마다 임의로 변형을 가함으로써 마치 훨씬 더 많은 이미지를 보고 공부하는 것과 같은 학습 효과를 내는 겁니다. 이를 통해 과적합 (overfitting), 즉 모델이 학습 데이터에만 맞춰지는 것을 방지하고, 새로운 이미지도 잘 분류할 수 있게 합니다.\n",
    "    \n",
    "    \n",
    "# 이미지 데이터를 숫자형 데이터로 변환하기 위해 필요한 파이썬 라이브러리는 다음과 같습니다.\n",
    "\n",
    "os\n",
    "cv2\n",
    "numpy\n",
    "sklearn\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   [ImageDataGenerator]\n",
    "    \n",
    "    \n",
    "    - 이런 전처리 과정을 돕기 위해 케라스는 ImageDataGenerator 클래스를 제공합니다. ImageDataGenerator는 이런 일을 할 수 있죠:\n",
    "\n",
    "    - 학습 도중에 이미지에 임의 변형 및 정규화 적용\n",
    "    - 변형된 이미지를 배치 단위로 불러올 수 있는 generator 생성.\n",
    "    - generator를 생성할 때 flow(data, labels), flow_from_directory(directory) 두 가지 함수를 사용합니다.\n",
    "    - fit_generator, evaluate_generator 함수를 이용하여 generator로 이미지를 불러와서 모델을 학습시킬 수 있습니다.\n",
    "   \n",
    "- rotation_range: 이미지 회전 범위 (degrees)\n",
    "- width_shift, height_shift: 그림을 수평 또는 수직으로 랜덤하게 평행 이동시키는 범위 (원본 가로, 세로 길이에 대한 비율 값)\n",
    "- rescale: 원본 영상은 0-255의 RGB 계수로 구성되는데, 이 같은 입력값은 모델을 효과적으로 학습시키기에 너무 높습니다 (통상적인 learning rate를 사용할 경우). 그래서 이를 1/255로 스케일링하여 0-1 범위로 변환시켜줍니다. 이는 다른 전처리 과정에 앞서 가장 먼저 적용됩니다.\n",
    "- shear_range: 임의 전단 변환 (shearing transformation) 범위\n",
    "- zoom_range: 임의 확대/축소 범위\n",
    "- horizontal_flip: True로 설정할 경우, 50% 확률로 이미지를 수평으로 뒤집습니다. 원본 이미지에 수평 비대칭성이 없을 때 효과적입니다. 즉, 뒤집어도 자연스러울 때 사용하면 좋습니다.\n",
    "- fill_mode 이미지를 회전, 이동하거나 축소할 때 생기는 공간을 채우는 방식\n",
    "케라스 공식 문서를 보시면 이외에도 다양한 인자가 있습니다.\n",
    "\n",
    "\n",
    "   [ImageDataGenerator 디버깅]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#레이어 개수, 그리고 레이어당 필터 개수가 적은 소규모 CNN을 학습시킬 겁니다. \n",
    "#학습 과정에서는 데이터 augmentation 및 드롭아웃 (dropout) 기법을 사용합니다. \n",
    "#드롭아웃은 과적합을 방지할 수 있는 또 다른 방법입니다. \n",
    "#하나의 레이어가 이전 레이어로부터 같은 입력을 두번 이상 받지 못하도록 하여 \n",
    "#데이터 augmentation과 비슷한 효과를 냅니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#https://rfriend.tistory.com/431"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense,Dropout,Flatten,MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np , pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass_dir = './recycle/glass'\n",
    "can_dir= './recycle/can'\n",
    "plastic_dir= './recycle/plastic'\n",
    "styrofoam_dir='./recycle/styrofoam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "len(os.listdir(glass_r))\n",
    "len(os.listdir(can_r))\n",
    "len(os.listdir(plastic_r))\n",
    "len(os.listdir(styrofoam_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.listdir(glass_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# glass 이름 지정및 사이즈 변경\n",
    "import cv2\n",
    "glass = cv2.imread(\"recycle/glass/gl_coke0.jpg\")\n",
    "print(glass.shape)\n",
    "\n",
    "title= list(os.listdir(\"recycle/glass/\"))  \n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glass 이름 지정및 사이즈 변경\n",
    "for i, re in enumerate(title):\n",
    "    glass = cv2.imread(\"recycle/glass/{}\".format(re))\n",
    "    resize_glass = cv2.resize(glass, (64, 64))\n",
    "    print(\"resize_glass.shape = {0}\".format(resize_glass.shape))   \n",
    "    cv2.imwrite('./recycle/edit/glass_/glass.{}.jpg'.format(i),resize_glass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can  이름 지정 및 사이즈\n",
    "\n",
    "title_can= list(os.listdir(\"recycle/can/\"))  \n",
    "title_can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, re in enumerate(title_can):\n",
    "    can = cv2.imread(\"recycle/can/{}\".format(re))\n",
    "    resize_can = cv2.resize(can, (64, 64))\n",
    "    print(\"resize_can.shape = {0}\".format(resize_can.shape))   \n",
    "    cv2.imwrite('./recycle/edit/can_/can.{}.jpg'.format(i),resize_can)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plastic  이름 지정 및 사이즈\n",
    "\n",
    "title_plastic = list(os.listdir(\"recycle/plastic/\"))  \n",
    "\n",
    "# plastic\n",
    "\n",
    "for i, re in enumerate(title_plastic):\n",
    "    plastic = cv2.imread(\"recycle/plastic/{}\".format(re))\n",
    "    resize_plastic = cv2.resize(plastic, (64, 64))\n",
    "    print(\"resize_plastic.shape = {0}\".format(resize_plastic.shape))   \n",
    "    cv2.imwrite('./recycle/edit/plastic_/plastic.{}.jpg'.format(i),resize_plastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# styrofoam  이름 지정 및 사이즈\n",
    "\n",
    "title_styrofoam = list(os.listdir(\"recycle/styrofoam/\"))  \n",
    "\n",
    "# styrofoam\n",
    "\n",
    "for i, re in enumerate(title_styrofoam):\n",
    "    styrofoam = cv2.imread(\"recycle/styrofoam/{}\".format(re))\n",
    "    resize_styrofoam = cv2.resize(styrofoam, (64, 64))\n",
    "    print(\"resize_styrofoam.shape = {0}\".format(resize_styrofoam.shape))   \n",
    "    cv2.imwrite('./recycle/edit/styrofoam_/styrofoam.{}.jpg'.format(i),resize_styrofoam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resize_glass.shape)\n",
    "print(resize_can.shape)\n",
    "print(resize_plastic.shape)\n",
    "print(resize_styrofoam.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화\n",
    "glass=resize_glass /255\n",
    "can = resize_can /255\n",
    "plastic = resize_plastic/255\n",
    "styrofoam = resize_styrofoam/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LABELING\n",
    "\n",
    "http://www.birc.co.kr/2018/02/26/%EC%8B%A4%EC%A0%9C-%EC%9D%B4%EB%AF%B8%EC%A7%80-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-cnn-%EB%AA%A8%EB%8D%B8-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##enumerate\n",
    "\n",
    "반복문 사용 시 몇 번째 반복문인지 확인이 필요할 수 있습니다. 이때 사용합니다.\n",
    "인덱스 번호와 컬렉션의 원소를 tuple형태로 반환합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t = [1, 5, 7, 33, 39, 52]\n",
    "for p in enumerate(t):\n",
    "    print(p)\n",
    "\n",
    "#(0, 1)\n",
    "#(1, 5)\n",
    "#(2, 7)\n",
    "#(3, 33)\n",
    "#(4, 39)\n",
    "#(5, 52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실패"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "image_dir ='./recycle/edited/'\n",
    "class_names =['glass','can','plastic','styrofoam']\n",
    "n_class = len(class_names)\n",
    "\n",
    "    \n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "pixels = image_w * image_h * 3\n",
    "\n",
    "X=[]\n",
    "y=[]\n",
    "\n",
    "for idx, sort in enumerate(class_names):\n",
    "    \n",
    "    #one-hot 돌리기.\n",
    "    label = [0 for i in range(n_class)]\n",
    "    label[idx] = 1\n",
    "    image_dir = image_dir +\"/\"+ sort\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    print(sort,'파일길이 :',len(files))\n",
    "    for i,f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert('RGB')\n",
    "        data = np.asarray(img)\n",
    "        \n",
    "        X.append(data)\n",
    "        y.append(label)\n",
    "        \n",
    "        if i % 100==0:\n",
    "            print(sort,\":\",f)\n",
    "            \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data, label _ 보류\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://www.birc.co.kr/2018/02/26/%EC%8B%A4%EC%A0%9C-%EC%9D%B4%EB%AF%B8%EC%A7%80-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-cnn-%EB%AA%A8%EB%8D%B8-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0/\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "TRAIN_DIR = './recycle/edit/'\n",
    "train_folder_list = array(os.listdir(TRAIN_DIR))\n",
    "print(train_folder_list)\n",
    "train_input = []\n",
    "train_label=[]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#문자열로 구성된 train_folder_list를 숫자형 리스트로 변환합니다\n",
    "integer_encoded = label_encoder.fit_transform(train_folder_list)\n",
    "#앞서 from sklearn.preprocessing import OneHotEncoder를 통해 불러온 \n",
    "#OneHotEncoder 함수를 onehot_encoder라는 변수로 호출합니다.\n",
    "one_hot_encoder = OneHotEncoder(sparse = False)\n",
    "#OneHotEncoder를 사용하기 위해 integer_encoded의 shape을 (10,)에서 (10,1)로 변환합니다. \n",
    "#integer_encoded를 출력하면 다음과 같습니다.\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded),1)\n",
    "#OneHotEncoder를 사용하여 integer_encode를 다음과 같이 변환하여\n",
    "#onehot_encoded 변수에 저장합니다.\n",
    "onehot_encoded = one_hot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "for index in range(len(train_folder_list)):\n",
    "    # path라는 변수에 TRAIN_DIR(D:/python3_project/MNIST_CNN/MNIST/trainingSet/)과\n",
    "    #train_folder_list의 n번째 원소를 합쳐서 path에 저장합니다.\n",
    "    # path 출력 예시는 다음과 같습니다.\n",
    "    path = os.path.join(TRAIN_DIR,train_folder_list[index])\n",
    "    print(path)\n",
    "    #‘/’ : path라는 변수에 ‘/’를 추가합니다. path 출력 예시는 다음과 같습니다.\n",
    "    path = path+'/'\n",
    "    #img_list 변수에 폴더 내 파일명을 저장합니다. \n",
    "    #img_list 출력 예시는 다음과 같습니다.\n",
    "    img_list = os.listdir(path)\n",
    "    print(img_list)\n",
    "    #img_path = os.path.join(path, img) : img_path에 정확한 이미지 경로를 저장합니다. \n",
    "    \n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path,img)\n",
    "        print(img_path)\n",
    "        img = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE) # 흑백으로 불러오기 \n",
    "        train_input.append([np.array(img)])\n",
    "        train_label.append([np.array(onehot_encoded[index])])\n",
    "        \n",
    "train_input = np.reshape(train_input,(-1,4096))\n",
    "train_label = np.reshape(train_label,(-1,4))\n",
    "train_input = np.array(train_input).astype(np.float32)\n",
    "train_label = np.array(train_label).astype(np.float32)\n",
    "\n",
    "np.save('train_data.npy',train_input)\n",
    "np.save('train_label.npy',train_label)\n",
    "\n",
    "\n",
    "data_set =[]\n",
    "data_set.append([train_input,train_label])\n",
    "\n",
    "print(data_set)\n",
    "\n",
    "print(train_input.shape)\n",
    "\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prubt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = data_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECYCLING IMAGE CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGE GENERATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os,glob,numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout,Activation,Dense\n",
    "from tensorflow.keras.layers import Flatten,Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, glob, numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glass 파일길이 : 1266\n",
      "can 파일길이 : 507\n",
      "plastic 파일길이 : 451\n",
      "styrofoam 파일길이 : 774\n",
      "ok 2998\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "image_dir ='C:/Users/ICT01_14/Documents/seoyoon/recycle/edit'\n",
    "class_names =['glass','can','plastic','styrofoam']\n",
    "n_class = len(class_names)\n",
    "\n",
    "    \n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "pixels = image_w * image_h * 3\n",
    "\n",
    "X=[]\n",
    "y=[]\n",
    "\n",
    "for idx, sort in enumerate(class_names):\n",
    "    \n",
    "    #one-hot 돌리기.\n",
    "    label = [0 for i in range(n_class)]\n",
    "    label[idx] = 1\n",
    "    \n",
    "    img_dir = image_dir +\"/\"+ sort\n",
    "    files = glob.glob(img_dir+\"/*.jpg\")\n",
    "    print(sort,'파일길이 :',len(files))\n",
    "    \n",
    "    for i,f in enumerate(files):\n",
    "        \n",
    "        img = Image.open(f)\n",
    "        img = img.convert('RGB')\n",
    "        img = img.resize((image_w,image_h))\n",
    "        data = np.asarray(img)\n",
    "        \n",
    "        X.append(data)\n",
    "        y.append(label)\n",
    "        \n",
    "#         if i % 100==0:\n",
    "#             print(sort,\":\",f)\n",
    "            \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "               \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "np.save(\"./recycle/numpy_data/multi_image_data.npy\", xy)\n",
    "\n",
    "print(\"ok\", len(y))\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = np.load(\"./recycle/numpy_data/multi_image_data.npy\",allow_pickle =True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "print(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = ['glass','can','plastic','styrofoam']\n",
    "n_class = len(class_name)\n",
    "\n",
    "X_train = X_train.astype(float)/255\n",
    "X_test = X_test.astype(float)/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with K.tf_ops.device('/device:GPU:0'):\n",
    "    model =Sequential()\n",
    "    model.add(Conv2D(32,(3,3),padding='same',input_shape = X_train.shape[1:],\n",
    "                    activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64,(3,3),padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256,activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_class,activation ='softmax'))\n",
    "    model.compilt(loss = 'categorical_crossentropy',optimizer='adam',\n",
    "                  metrics = ['accuracy'])\n",
    "    model_dir ='./recycle/model'\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/lsjsj92/keras_basic/blob/master/7.%20predict_multi_img_with_CNN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "734px",
    "left": "21px",
    "top": "0px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
