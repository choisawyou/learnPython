{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaggle code\n",
    "\n",
    "- (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pylearn.datasets.dense_design_matrix'; 'pylearn.datasets' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-318c23379d85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpylearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_design_matrix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDefaultViewConverter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpylearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_design_matrix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDenseDesignMatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpylearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pylearn.datasets.dense_design_matrix'; 'pylearn.datasets' is not a package"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A Pylearn2 Dataset class for accessing the data for the\n",
    "facial expression recognition Kaggle contest for the ICML\n",
    "2013 workshop on representation learning.\n",
    "\"\"\"\n",
    "__authors__ = \"Ian Goodfellow\"\n",
    "__copyright__ = \"Copyright 2013, Universite de Montreal\"\n",
    "__credits__ = [\"Ian Goodfellow\"]\n",
    "__license__ = \"3-clause BSD\"\n",
    "__maintainer__ = \"LISA Lab\"\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from pylearn.datasets.dense_design_matrix import DefaultViewConverter\n",
    "from pylearn.datasets.dense_design_matrix import DenseDesignMatrix\n",
    "from pylearn.utils.string_utils import preprocess\n",
    "\n",
    "class EmotionsDataset(DenseDesignMatrix):\n",
    "    \"\"\"\n",
    "    A Pylearn2 Dataset class for accessing the data for the\n",
    "    facial expression recognition Kaggle contest for the ICML\n",
    "    2013 workshop on representation learning.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, which_set,\n",
    "            base_path = '${PYLEARN2_DATA_PATH}/icml_2013_emotions',\n",
    "            start = None,\n",
    "            stop = None,\n",
    "            preprocessor = None,\n",
    "            fit_preprocessor = False,\n",
    "            axes = ('b', 0, 1, 'c'),\n",
    "            fit_test_preprocessor = False):\n",
    "        \"\"\"\n",
    "        which_set: A string specifying which portion of the dataset\n",
    "            to load. Valid values are 'train' or 'public_test'\n",
    "        base_path: The directory containing the .csv files from kaggle.com.\n",
    "                This directory should be writable; if the .csv files haven't\n",
    "                already been converted to npy, this class will convert them\n",
    "                to save memory the next time they are loaded.\n",
    "        fit_preprocessor: True if the preprocessor is allowed to fit the\n",
    "                   data.\n",
    "        fit_test_preprocessor: If we construct a test set based on this\n",
    "                    dataset, should it be allowed to fit the test set?\n",
    "        \"\"\"\n",
    "\n",
    "        self.test_args = locals()\n",
    "        self.test_args['which_set'] = 'public_test'\n",
    "        self.test_args['fit_preprocessor'] = fit_test_preprocessor\n",
    "        del self.test_args['start']\n",
    "        del self.test_args['stop']\n",
    "        del self.test_args['self']\n",
    "        del self.test_args['__class__']\n",
    "\n",
    "        files = {'train': 'train.csv', 'public_test' : 'test.csv'}\n",
    "\n",
    "        try:\n",
    "            filename = files[which_set]\n",
    "        except KeyError:\n",
    "            raise ValueError(\"Unrecognized dataset name: \" + which_set)\n",
    "\n",
    "        path = base_path + '/' + filename\n",
    "\n",
    "        path = preprocess(path)\n",
    "\n",
    "        X, y = self._load_data(path, which_set == 'train')\n",
    "\n",
    "\n",
    "        if start is not None:\n",
    "            assert which_set != 'test'\n",
    "            assert isinstance(start, int)\n",
    "            assert isinstance(stop, int)\n",
    "            assert start >= 0\n",
    "            assert start < stop\n",
    "            assert stop <= X.shape[0]\n",
    "            X = X[start:stop, :]\n",
    "            if y is not None:\n",
    "                y = y[start:stop, :]\n",
    "\n",
    "        view_converter = DefaultViewConverter(shape=[48,48,1], axes=axes)\n",
    "\n",
    "        if y is None:\n",
    "            y_labels = None\n",
    "        else:\n",
    "            y_labels = 7\n",
    "        super(EmotionsDataset, self).__init__(X=X, y=y, y_labels=y_labels, view_converter=view_converter)\n",
    "\n",
    "        if preprocessor:\n",
    "            preprocessor.apply(self, can_fit=fit_preprocessor)\n",
    "\n",
    "    def adjust_for_viewer(self, X):\n",
    "        return (X - 127.5) / 127.5\n",
    "\n",
    "    def get_test_set(self):\n",
    "        return EmotionsDataset(**self.test_args)\n",
    "\n",
    "    def _load_data(self, path, expect_labels):\n",
    "\n",
    "        assert path.endswith('.csv')\n",
    "\n",
    "        # If a previous call to this method has already converted\n",
    "        # the data to numpy format, load the numpy directly\n",
    "        X_path = path[:-4] + '.X.npy'\n",
    "        Y_path = path[:-4] + '.Y.npy'\n",
    "        if os.path.exists(X_path):\n",
    "            X = np.load(X_path)\n",
    "            if expect_labels:\n",
    "                y = np.load(Y_path)\n",
    "            else:\n",
    "                y = None\n",
    "            return X, y\n",
    "\n",
    "        # Convert the .csv file to numpy\n",
    "        csv_file = open(path, 'r')\n",
    "\n",
    "        reader = csv.reader(csv_file)\n",
    "\n",
    "        # Discard header\n",
    "        row = next(reader)\n",
    "\n",
    "        y_list = []\n",
    "        X_list = []\n",
    "\n",
    "        for row in reader:\n",
    "            if expect_labels:\n",
    "                y_str, X_row_str = (row[0], row[1])\n",
    "                y = int(y_str)\n",
    "                y_list.append([y])\n",
    "            else:\n",
    "                X_row_str = row[1]\n",
    "            X_row_strs = X_row_str.split(' ')\n",
    "            X_row = [float(x) for x in X_row_strs]\n",
    "            X_list.append(X_row)\n",
    "\n",
    "        X = np.asarray(X_list).astype('float32')\n",
    "        if expect_labels:\n",
    "            y = np.asarray(y_list)\n",
    "        else:\n",
    "            y = None\n",
    "\n",
    "        np.save(X_path, X)\n",
    "        if y is not None:\n",
    "            np.save(Y_path, y)\n",
    "\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csv to jpg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-12-d934e74363e8>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-d934e74363e8>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    print('Usage: python cv_to_img.py [output_path]')\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    if len(sys.argv) < 2:\n",
    "    print('Usage: python cv_to_img.py [output_path]')\n",
    "return -1\n",
    "\n",
    "output_path = sys.argv[1]`\n",
    "\n",
    "if os.path.exists(output_path):\n",
    "\n",
    "    os.system('rm -rf {}'.format(output_path))\n",
    "\n",
    "os.system('mkdir {}'.format(output_path))\n",
    "\n",
    "label_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "#data = pd.read_csv('fer2013.csv', delimiter=',')\n",
    "data = np.genfromtxt('fer2013.csv',delimiter=',',dtype=None)\n",
    "\n",
    "labels = data[1:,0].astype(np.int32)\n",
    "image_buffer = data[1:,1]\n",
    "images = np.array([np.fromstring(image, np.uint8, sep=' ') for image in image_buffer])\n",
    "usage = data[1:,2]\n",
    "dataset = zip(labels, images, usage)\n",
    "for i, d in enumerate(dataset):\n",
    "    usage_path = os.path.join(output_path, d[-1])\n",
    "    label_path = os.path.join(usage_path, label_names[d[0]])\n",
    "    img = d[1].reshape((48,48))\n",
    "    img_name = '%08d.jpg' % i\n",
    "    img_path = os.path.join(label_path, img_name)\n",
    "    if not os.path.exists(usage_path):\n",
    "        os.system('mkdir {}'.format(usage_path))\n",
    "    if not os.path.exists(label_path):\n",
    "        os.system('mkdir {}'.format(label_path))\n",
    "    cv2.imwrite(img_path, img)\n",
    "    print 'Write {}'.format(img_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-b16c8726284f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-b16c8726284f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    $mkdir fer_images\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "$mkdir fer_images\n",
    "\n",
    "fer_data=pd.read_csv('fer2013/fer2013.csv',delimiter=',')\n",
    "\n",
    "def save_fer_img():\n",
    "\n",
    "for index,row in fer_data.iterrows():\n",
    "pixels=np.asarray(list(row['pixels'].split(' ')),dtype=np.uint8)\n",
    "img=pixels.reshape((48,48))\n",
    "pathname=os.path.join('fer_images',str(index)+'.jpg')\n",
    "cv2.imwrite(pathname,img)\n",
    "print('image saved ias {}'.format(pathname))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실시간 이미지 처리 \n",
    "##https://www.youtube.com/watch?v=DtBu1u5aBsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# import tensorflow\n",
    "# import keras\n",
    "# import numpy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 3 columns):\n",
      "emotion    35887 non-null int64\n",
      " Usage     35887 non-null object\n",
      " pixels    35887 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 841.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense,Dropout,Activation,Flatten\n",
    "# from keras.layers import Conv2D,Maxpooling2D,BatchNormalization\n",
    "# from keras.losses import catergoical_crossentropy\n",
    "# from keras.optimiezrs import Adam\n",
    "# from keras.regularizers import l2\n",
    "# from keras.utils import np_utils\n",
    "\n",
    "df = pd.read_csv('fer2013.csv')\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>Usage</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Training</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Training</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Training</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion     Usage                                             pixels\n",
       "0        0  Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1        0  Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2        2  Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3        4  Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4        6  Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " print(df.head())\n",
    "    \n",
    "print(df['Usage'].value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "233.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
