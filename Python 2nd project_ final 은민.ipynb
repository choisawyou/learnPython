{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import os, glob, numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import array\n",
    "from PIL import Image as img\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:/Users/ICT01_09/Documents/CNN'\n",
    "categories = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories   # 폴더명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = len(categories)\n",
    "nb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread(\"st/st0.jpg\")\n",
    "#print(img.shape)  # 확인 \n",
    "#title = list(os.listdir(\"st/\"))\n",
    "\n",
    "#for i, re in enumerate(title):             # 번호 생성 \n",
    "#    img = cv2.imread(\"st/{}\".format(re))  # st/파일명 을 말한다 \n",
    "#    resize_img = cv2.resize(img, (64, 64))\n",
    "#    print(\"resize_img.shape = {0}\".format(resize_img.shape))   \n",
    "#    cv2.imwrite('styrofoam/st.{}.jpg'.format(i),resize_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for index in range(len(categories)):\n",
    "#    path = os.path.join(data_dir, categories[index])\n",
    "#    path = path + '/'\n",
    "#    print(path)\n",
    "#    img_list = os.listdir(path)\n",
    "#    for img in img_list:\n",
    "#        img_path = os.path.join(path, img)\n",
    "#        img = cv2.imread(img_path)\n",
    "#        img = cv2.resize(img,(64,64))\n",
    "#        train_input.append([np.array(img)])\n",
    "#        train_label.append([np.array(onehot_encoder[index])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 크기 줄여주기 \n",
    "image_w = 128\n",
    "image_h = 128\n",
    "\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for idex, categorie in enumerate(categories):\n",
    "    \n",
    "    #one-hot 돌리기.\n",
    "    label = [0 for i in range(nb_classes)]\n",
    "    label[idex] = 1\n",
    "\n",
    "    image_dir = data_dir + \"/\" + categorie + '/'\n",
    "    \n",
    "    for top, dir, f in os.walk(image_dir):\n",
    "        for filename in f:\n",
    "            print(image_dir+filename)\n",
    "            img = cv2.imread(image_dir+filename)\n",
    "            img= cv2.resize(img,None,fx=image_w/img.shape[0], fy=image_h/img.shape[1])\n",
    "            X.append(img/256)\n",
    "            Y.append(label)\n",
    "            \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "xy = (X_train, X_test, Y_train, Y_test)\n",
    "np.save(\"./img_data.npy\", xy)\n",
    "\n",
    "print(\"ok\", len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 전처리 ( 수작업)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 이미지 -> 숫자형 데이터로 변환 \n",
    "# 필요한 라이브러리 : os, cv2, numpy, sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os   # >> 디렉토리 경로 호출\n",
    "import cv2   # >> 이미지 파일 호출\n",
    "import numpy as np   # >> 데이터 처리에 사용\n",
    "from numpy import array  # >> 리스트를 array 형태로 만든다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder  #>> 문자로된 폴더리스트를 숫자형 array로 \n",
    "from sklearn.preprocessing import OneHotEncoder #>> 숫자형 array 를 one-hot-encode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:/Users/ICT01_09/Documents/train/'  # 이미지 데이터셋의 경로\n",
    "folder_list = array(os.listdir(data_dir))  # 내부 폴더명을 array 형태로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(folder_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []  # X값 \n",
    "Y = []  # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(folder_list)\n",
    "# 문자열로 구성된 folder_list 를 숫자형 리스트로 변환\n",
    "print(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "# 위에서 부른 OneHotEncoder 함수를 onehot_encoder 라는 변수로 호출\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded),1)\n",
    "##>> (4.) 에서 (4,1) 로 변한다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)  # integer_encoded 를 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_w= 128\n",
    "image_h = 128\n",
    "\n",
    "for index in range(len(folder_list)): # 0~3까지 4번 반복된다\n",
    "    path = os.path.join(data_dir, folder_list[index] )\n",
    "    path = path+'/'\n",
    "    img_list = os.listdir(path)  # 폴더내 파일명을 저장한다(모든파일명 호출) \n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path,img)  # img_path : 정확한 이미지 경로\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여기서부터 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 전처리 ( 수작업)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 이미지 이름 바꾸기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#공부하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 이미지 부풀리기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://tykimos.github.io/2017/06/10/CNN_Data_Augmentation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더별 원래 데이터 갯수를 확인해보자  \n",
    "import os, glob, numpy as np\n",
    "from numpy import array\n",
    "data_dir = \"C:/Users/ICT01_09/Documents/train/\" # 폴더\n",
    "categories = array(os.listdir(data_dir))\n",
    "\n",
    "for idx, trash in enumerate(categories):  \n",
    "    image_dir = data_dir + '/' + trash   # 4개 폴더 주소 출력 \n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    print(trash, \" 파일 길이 : \", len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터를 부풀리자!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 랜덤시드 고정시키기\n",
    "np.random.seed(5)\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   rotation_range=15,  # 원본이미지 회전\n",
    "                                   width_shift_range=0.1, # 수평방향이동\n",
    "                                   height_shift_range=0.1, # 수직방향 이동\n",
    "                                   shear_range=0.5,           #시계반대방향변형\n",
    "                                   zoom_range=[0.8, 2.0],  # 확대, 축소\n",
    "                                   horizontal_flip=True, # 수평방향 뒤집기\n",
    "                                   vertical_flip=True, # 수직방향 뒤집기 \n",
    "                                   fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#먼저 can 의 이미지 늘리기 (507-> 10000)\n",
    "for idx, trash in enumerate(categories):  \n",
    "    image_dir = data_dir + '/' + trash    # 4개 폴더 주소 출력 \n",
    "    files = glob.glob(image_dir+\"/*.jpg\") # 모든 사진 이름 출력\n",
    "    if trash == 'can':                     # can 폴더 사진만 가져온다 \n",
    "        for i in range(len(files)):\n",
    "            img = load_img(files[i])  # 모든 can 의 이미지를 불러왔다 \n",
    "            x = img_to_array(img)\n",
    "            x = x.reshape((1,) + x.shape)\n",
    "            i=0\n",
    "            for batch in train_datagen.flow(x,batch_size=1, save_to_dir = 'C:/Users/ICT01_09/Documents/train/new_can'\n",
    "                                            ,save_prefix = 'tri', save_format='jpg'):\n",
    "                i += 1\n",
    "                if i > 250:  # 200 이면 9999\n",
    "                    break\n",
    "\n",
    "\n",
    "image_dir = data_dir + '/' + 'new_can'   # 4개 폴더 주소 출력 \n",
    "files = glob.glob(image_dir+\"/*.jpg\")\n",
    "print(\" 파일 길이 : \", len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#먼저 glass의 이미지 늘리기 (1266-> 10000)\n",
    "for idx, trash in enumerate(categories):  \n",
    "    image_dir = data_dir + '/' + trash    # 4개 폴더 주소 출력 \n",
    "    files = glob.glob(image_dir+\"/*.jpg\") # 모든 사진 이름 출력\n",
    "    if trash == 'glass':                     # glass 폴더 사진만 가져온다 \n",
    "        for i in range(len(files)):\n",
    "            img = load_img(files[i])  # 모든 glass 의 이미지를 불러왔다 \n",
    "            x = img_to_array(img)\n",
    "            x = x.reshape((1,) + x.shape)\n",
    "            i=0\n",
    "            for batch in train_datagen.flow(x,batch_size=1, save_to_dir = 'C:/Users/ICT01_09/Documents/train/new_glass'\n",
    "                                            ,save_prefix = 'tri', save_format='jpg'):\n",
    "                i += 1\n",
    "                if i > 100:\n",
    "                    break\n",
    "\n",
    "\n",
    "image_dir = data_dir + '/' + 'new_glass'   # 4개 폴더 주소 출력 \n",
    "files = glob.glob(image_dir+\"/*.jpg\")\n",
    "print(\" 파일 길이 : \", len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#먼저 pet 의 이미지 늘리기 (-> 10000)\n",
    "for idx, trash in enumerate(categories):  \n",
    "    image_dir = data_dir + '/' + trash    # 4개 폴더 주소 출력 \n",
    "    files = glob.glob(image_dir+\"/*.jpg\") # 모든 사진 이름 출력\n",
    "    if trash == 'pet':                     # can 폴더 사진만 가져온다 \n",
    "        for i in range(len(files)):\n",
    "            img = load_img(files[i])  # 모든 can 의 이미지를 불러왔다 \n",
    "            x = img_to_array(img)\n",
    "            x = x.reshape((1,) + x.shape)\n",
    "            i=0\n",
    "            for batch in train_datagen.flow(x,batch_size=1, save_to_dir = 'C:/Users/ICT01_09/Documents/train/new_pet'\n",
    "                                            ,save_prefix = 'tri', save_format='jpg'):\n",
    "                i += 1\n",
    "                if i > 200:\n",
    "                    break\n",
    "\n",
    "\n",
    "image_dir = data_dir + '/' + 'new_pet'   # 4개 폴더 주소 출력 \n",
    "files = glob.glob(image_dir+\"/*.jpg\")\n",
    "print(\" 파일 길이 : \", len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#먼저 styrofoam 의 이미지 늘리기 (451-> 10000)\n",
    "for idx, trash in enumerate(categories):  \n",
    "    image_dir = data_dir + '/' + trash    # 4개 폴더 주소 출력 \n",
    "    files = glob.glob(image_dir+\"/*.jpg\") # 모든 사진 이름 출력\n",
    "    if trash == 'styrofoam':                     # can 폴더 사진만 가져온다 \n",
    "        for i in range(len(files)):\n",
    "            img = load_img(files[i])  # 모든 can 의 이미지를 불러왔다 \n",
    "            x = img_to_array(img)\n",
    "            x = x.reshape((1,) + x.shape)\n",
    "            i=0\n",
    "            for batch in train_datagen.flow(x,batch_size=1, save_to_dir = 'C:/Users/ICT01_09/Documents/train/new_styrofoam'\n",
    "                                            ,save_prefix = 'tri', save_format='jpg'):\n",
    "                i += 1\n",
    "                if i > 200:\n",
    "                    break\n",
    "\n",
    "\n",
    "image_dir = data_dir + '/' + 'new_styrofoam'   # 4개 폴더 주소 출력 \n",
    "files = glob.glob(image_dir+\"/*.jpg\")\n",
    "print(\" 파일 길이 : \", len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  이미지 배열화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new_can', 'new_pet', 'new_glass', 'new_styrofoam']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np   # >> 데이터 처리에 사용\n",
    "from numpy import array\n",
    "\n",
    "data_dir = \"C:/Users/ICT01_09/Documents/train/\" # 폴더\n",
    "\n",
    "#categories = array(os.listdir(data_dir)) # 각 카테고리 폴더에서 불러오기\n",
    "categories = ['new_can', 'new_pet', 'new_glass', 'new_styrofoam']\n",
    "print(categories)\n",
    "nb_classes = len(categories)\n",
    "print(nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_w = 64; image_h = 64  # 이미지 크기 : 64x64 \n",
    "X = []\n",
    "Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, trash in enumerate(categories):     #>>idx=0,1,2,3 생성/ trash 는 폴더이름 \n",
    "    label = [0 for i in range(nb_classes)]   # label 을 0으로 초기화->[0,0,0,0]\n",
    "    label[idx]=1  \n",
    "      #[1, 0, 0, 0] \n",
    "      #[0, 1, 0, 0]\n",
    "      #[0, 0, 1, 0]\n",
    "      #[0, 0, 0, 1]\n",
    "    image_dir = data_dir + '/' + trash   # 4개 폴더 주소 출력 \n",
    "    files = glob.glob(image_dir+\"/*.jpg\") # 모든 사진 주소 가져온다 \n",
    "    \n",
    "    for i, f in enumerate(files): #그룹별 사진파일마다 0부터 숫자부여(i는 숫자, f는 주소)\n",
    "        img = Image.open(f) # 이미지 하나하나 불러온다고 생각하자 \n",
    "        img = img.convert('RGB')  # 그레이로 하겠다\n",
    "        img = img.resize((image_w, image_h)) #사이즈 다시 설정\n",
    "        data = np.asarray(img)  # img 값을 넘파이 라이브러리 이용해 가지고와서 저장한다\n",
    "        \n",
    "        X.append(data)  # X data\n",
    "        Y.append(label) # Y 는 리스트형으로 저장 \n",
    "        \n",
    "        \n",
    "        #if i % 3500 == 0: # 1500번째 사진을 가져온다 ( 확인용 ) \n",
    "         #   print(trash,\":\",f)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "## Y 는 아래처럼 저장이 된다 \n",
    "## can 이면 [1,0,0,0]\n",
    "## glass이면  [0,1,1,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 이미지 (훈련데이터/ 테스트 데이터 나누기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "40000\n",
      "30000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X,Y)\n",
    "print(len(X))\n",
    "print(len(Y))\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy=(X_train,X_test,y_train,y_test)\n",
    "np.save(\"./multi_image_data.npy\",xy)  ## numpy 라이브러리 이용해서 외부파일로 저장한다\n",
    "                                     # 배열을 저장함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_save_load = np.load('./multi_image_data.npy')\n",
    "#x_save_load  # 배열 부른것 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 메모리 절약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, glob, numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# 메모리 절약하기 \n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.90\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "X_train, X_test, y_train, y_test = np.load('./multi_image_data.npy',allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 64, 64, 3)\n",
      "30000\n",
      "(10000, 64, 64, 3)\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train.shape[0])\n",
    "print(X_test.shape)\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(float)/255\n",
    "X_test = X_test.astype(float)/ 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 모델링\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델1 : 컨볼루션층2개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ICT01_09\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with K.tf_ops.device('/device:GPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())  # flatten 시킨다 \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # 오차함수는 categorical_crossentropy 를 사용하고\n",
    "    # 최적화함수는 adam 을 사용한다\n",
    "    # metrics -> 평가기준을 말한다 (학습과정중 제대로학습하는지) ,일반적으로 accuracy 를 삽입한다 )\n",
    "    # --> 내부적으로 categorical_accuracy 함수를 이용하여 정확도 계산이 가능하다 \n",
    "    \n",
    "    \n",
    "    \n",
    "    # 모델의 성과를 저장하고, 모델의 최적화단계에서 학습을 자동중단하게 설정\n",
    "    #--> 10회 이상 모델의 성과 향상이 없으면 자동으로 학습이 중단된다 \n",
    "    model_dir = 'C:/Users/ICT01_09/Documents/model'\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    model_path = model_dir + '/multi_img_classification.model'\n",
    "    checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)   # 과적합된다는 신호가 오는데 6번정도오면 끊는다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<학습 조기종료시키기>\n",
    "# https://tykimos.github.io/2017/07/09/Early_Stopping/\n",
    "# 과적합을 방지하기 위해 조기 종료한다 \n",
    "#>> EarlyStopping 이라는 함수를 사용하여, 더 이상의 개선의 여지가 없을때 학습 종료\n",
    "#>> fit 함수에서 Earlystopping 이라는 콜백함수를 설정하면 된다 \n",
    "\n",
    "#checkpoint 를 확인해보자 \n",
    "#monitor='val_loss' ( 관찰하고자 하는 항목 ) \n",
    "#verbose : 얼마나 자세하게 정보를 표현할 것인가 ( 0,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 4,214,980\n",
      "Trainable params: 4,214,980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ICT01_09\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "24000/24000 [==============================] - 70s 3ms/step - loss: 0.8621 - accuracy: 0.6277 - val_loss: 0.6638 - val_accuracy: 0.7195\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66382, saving model to C:/Users/ICT01_09/Documents/model/multi_img_classification.model\n",
      "Epoch 2/50\n",
      "24000/24000 [==============================] - 68s 3ms/step - loss: 0.6100 - accuracy: 0.7393 - val_loss: 0.5485 - val_accuracy: 0.7810\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66382 to 0.54852, saving model to C:/Users/ICT01_09/Documents/model/multi_img_classification.model\n",
      "Epoch 3/50\n",
      "24000/24000 [==============================] - 72s 3ms/step - loss: 0.5036 - accuracy: 0.7931 - val_loss: 0.5129 - val_accuracy: 0.7763\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.54852 to 0.51285, saving model to C:/Users/ICT01_09/Documents/model/multi_img_classification.model\n",
      "Epoch 4/50\n",
      "24000/24000 [==============================] - 70s 3ms/step - loss: 0.4255 - accuracy: 0.8303 - val_loss: 0.3860 - val_accuracy: 0.8837\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.51285 to 0.38595, saving model to C:/Users/ICT01_09/Documents/model/multi_img_classification.model\n",
      "Epoch 5/50\n",
      "24000/24000 [==============================] - 69s 3ms/step - loss: 0.3567 - accuracy: 0.8622 - val_loss: 0.3053 - val_accuracy: 0.8970\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.38595 to 0.30530, saving model to C:/Users/ICT01_09/Documents/model/multi_img_classification.model\n",
      "Epoch 6/50\n",
      "24000/24000 [==============================] - 70s 3ms/step - loss: 0.3163 - accuracy: 0.8775 - val_loss: 0.3466 - val_accuracy: 0.8840\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30530\n",
      "Epoch 7/50\n",
      "24000/24000 [==============================] - 71s 3ms/step - loss: 0.2842 - accuracy: 0.8917 - val_loss: 0.3495 - val_accuracy: 0.8855\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.30530\n",
      "Epoch 8/50\n",
      "24000/24000 [==============================] - 72s 3ms/step - loss: 0.2629 - accuracy: 0.9004 - val_loss: 0.2845 - val_accuracy: 0.9125\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.30530 to 0.28447, saving model to C:/Users/ICT01_09/Documents/model/multi_img_classification.model\n",
      "Epoch 9/50\n",
      "24000/24000 [==============================] - 70s 3ms/step - loss: 0.2351 - accuracy: 0.9107 - val_loss: 0.2776 - val_accuracy: 0.9082\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.28447 to 0.27757, saving model to C:/Users/ICT01_09/Documents/model/multi_img_classification.model\n",
      "Epoch 10/50\n",
      "24000/24000 [==============================] - 71s 3ms/step - loss: 0.2197 - accuracy: 0.9205 - val_loss: 0.2667 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.27757 to 0.26675, saving model to C:/Users/ICT01_09/Documents/model/multi_img_classification.model\n",
      "Epoch 11/50\n",
      "24000/24000 [==============================] - 70s 3ms/step - loss: 0.2019 - accuracy: 0.9267 - val_loss: 0.2895 - val_accuracy: 0.9058\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26675\n",
      "Epoch 12/50\n",
      "24000/24000 [==============================] - 73s 3ms/step - loss: 0.1996 - accuracy: 0.9266 - val_loss: 0.2330 - val_accuracy: 0.9258\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.26675 to 0.23298, saving model to C:/Users/ICT01_09/Documents/model/multi_img_classification.model\n",
      "Epoch 13/50\n",
      "24000/24000 [==============================] - 72s 3ms/step - loss: 0.1853 - accuracy: 0.9302 - val_loss: 0.2832 - val_accuracy: 0.9047\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.23298\n",
      "Epoch 14/50\n",
      "24000/24000 [==============================] - 70s 3ms/step - loss: 0.1626 - accuracy: 0.9420 - val_loss: 0.1982 - val_accuracy: 0.9388\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.23298 to 0.19819, saving model to C:/Users/ICT01_09/Documents/model/multi_img_classification.model\n",
      "Epoch 15/50\n",
      "24000/24000 [==============================] - 67s 3ms/step - loss: 0.1516 - accuracy: 0.9470 - val_loss: 0.2520 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.19819\n",
      "Epoch 16/50\n",
      "24000/24000 [==============================] - 68s 3ms/step - loss: 0.1495 - accuracy: 0.9476 - val_loss: 0.2631 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.19819\n",
      "Epoch 17/50\n",
      "24000/24000 [==============================] - 68s 3ms/step - loss: 0.1539 - accuracy: 0.9462 - val_loss: 0.2299 - val_accuracy: 0.9342\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.19819\n",
      "Epoch 18/50\n",
      "24000/24000 [==============================] - 68s 3ms/step - loss: 0.1472 - accuracy: 0.9458 - val_loss: 0.2041 - val_accuracy: 0.9417\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.19819\n",
      "Epoch 19/50\n",
      "24000/24000 [==============================] - 69s 3ms/step - loss: 0.1297 - accuracy: 0.9544 - val_loss: 0.2051 - val_accuracy: 0.9495\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.19819\n",
      "Epoch 20/50\n",
      "24000/24000 [==============================] - 72s 3ms/step - loss: 0.1294 - accuracy: 0.9544 - val_loss: 0.2302 - val_accuracy: 0.9370\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.19819\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_split=0.2, callbacks=[checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit 함수의 결과\n",
    "# loss(에포크마다 훈련 손실값), acc(에포크마다 훈련 정확도),\n",
    "# val_loss(에포크마다 검증 손실값), val_acc(에포크마다 검증 정확도) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 8s 810us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22883072189688683, 0.9395999908447266]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 8s 770us/step\n",
      "정확도 : 0.9396\n"
     ]
    }
   ],
   "source": [
    "print(\"정확도 : %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델학습 과정 표시하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()  # x축은 에포크수, y 축은 손실값 \n",
    "acc_ax = loss_ax.twinx()   \n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss') # 훈련 손실값 (노란색)\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss') #검증(val=validation) 손실값( 빨간색)\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['accuracy'], 'b', label='train acc') #훈련 정확도 ( 파란색)\n",
    "acc_ax.plot(history.history['val_accuracy'], 'g', label='val acc')# 검증정확도(녹색) \n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch =50 이였는데, 20에서 멈춤 ( 자기딴에는 과적합이라고 생각해서 )\n",
    "# epochs 값이 지나치게 클 수록 과적합이 발생할 수 있다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실값 작을수록 좁다 . 손실값을 최소화하도록 optimizer 을 쓴다\n",
    "# https://tykimos.github.io/2017/07/09/Training_Monitoring/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 그림을 넣고 예측해보자 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"C:/Users/ICT01_09/Documents/train/other_test\"\n",
    "image_w = 64\n",
    "image_h = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "filenames = []\n",
    "files = glob.glob(test_dir+\"/*.*\") # 모든 파일이 출력된다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, f in enumerate(files):  \n",
    "    img = Image.open(f)\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = img.resize((image_w, image_h))\n",
    "    data = np.asarray(img)\n",
    "    filenames.append(f)\n",
    "    \n",
    "    X.append(data)\n",
    "\n",
    "X= np.array(X)\n",
    "model = load_model(\"./model/multi_img_classification.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 imag3.jpg이미지는 유리로 추정됩니다.\n",
      "해당 image1.jpg이미지는 캔로 추정됩니다.\n",
      "해당 image2.jpg이미지는 유리로 추정됩니다.\n",
      "해당 image4.jpg이미지는 캔로 추정됩니다.\n",
      "해당 image5.jpg이미지는 유리로 추정됩니다.\n",
      "해당 images.jpg이미지는 캔로 추정됩니다.\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "cnt = 0\n",
    "for i in prediction:\n",
    "    pre_ans = i.argmax()  # 예측 레이블\n",
    "    #print(i)\n",
    "    #print(pre_ans)\n",
    "    pre_ans_str = ''\n",
    "    if pre_ans == 0: pre_ans_str = \"캔\"\n",
    "    elif pre_ans == 1: pre_ans_str = \"플라스틱\"\n",
    "    elif pre_ans == 2: pre_ans_str = \"유리\"\n",
    "    else: pre_ans_str = \"스티로품\"\n",
    "    if i[0] >= 0.8 : print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[1] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"으로 추정됩니다.\")\n",
    "    if i[2] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[3] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델링2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), input_shape=X_train.shape[1:],padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dense(nb_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " optimizer='adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-e0cba49b0cba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'optimizers' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train,epochs=30,batch_size=32, epochs=50,validation_split=0.2,\n",
    "         callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델링1 : 간단한 컨브넷 만들기( conv2d, maxpooling2d 층을 쌓아올렸다) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3,3), input_shape=(64,64,3), activation='relu'))\n",
    "# -> input 으로 64x64x3 이 들어간다.(input height, input width, input channel=색)  \n",
    "# -> 3x3 크기의 필터 32개를 사용한다.\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv2d, Maxpooling2D 의 출력은 (height, width, channels ) \n",
    "# 마지막 층의 (12,12,64) 를 완전 연결층에 주입한다 ( flatten 시켜서 3d 출력을 1d 텐서로 만든다 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(128,activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(4, activation='softmax')) # 4개의 클래스로 분류해보기 위해 마지막 층의 출력 크기를 4로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " model.summary() #>> (12,12,64) 가 (9216,) 크기의 벡터로 펼쳐진후 dense 층에 주입되었음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##훈련+ 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = np.load('./multi_image_data.npy',allow_pickle=True)\n",
    "print(X_train.shape)\n",
    "print(X_train.shape[0])\n",
    "print(X_test.shape)\n",
    "#print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255 \n",
    "X_test = X_test.astype('float32')/ 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = tf.reshape(X_train,[-1,64,64,1])\n",
    "\n",
    "#X_test = tf.reshape(X_test,[-1,64,64,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,4) # 활성화함수를 적용하기 위해 원핫인코딩한다고 생각하면 될듯 \n",
    "y_test = to_categorical(y_test,4)\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#신경망의 성능을 개선하기 위해 하는 것\n",
    "#https://datascienceschool.net/view-notebook/f18248a467e94c6483783afc93d08af9/\n",
    "# https://tykimos.github.io/2017/09/24/Custom_Metric/\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#1.  RMSprop 옵티마이저 사용\n",
    "#2.  loss인수를 설정하여 크로스 엔트로피 사용\n",
    "#3.  metrics -> 평가기준을 말한다 (학습과정중 제대로학습하는지) ,일반적으로 accuracy 를 삽입한다 )\n",
    "#   --> 내부적으로 categorical_accuracy 함수를 이용하여 정확도 계싼이 가능하다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train,epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train[:,:,-1],y_train[:,:,-1], steps_per_epoch=5,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu'))\n",
    "# 3x3 크기의 필터 32개 사용 , 활성화 함수는 relu 를 사용 ( input 으로는 64x64x3 이들어감)\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "    \n",
    "model.add(Conv2D(64,(3,3),padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 완전연결층 \n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('정확도 : %.4f' % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with K.tf_ops.device('/device:GPU:0'): # 디바이스 현재 GPU 없이 CPU로 구동중\n",
    "    model = Sequential() \n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu'))\n",
    "    # 3x3 크기의 필터 32개 사용 , 활성화 함수는 relu 를 사용 ( input 으로는 64x64x3 이들어감)\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64,(3,3),padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # 완전연결층 \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model_dir = './model'\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    model_path = model_dir + '/multi_img_classification.model'\n",
    "    checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2= model\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "def compile_and_train(model, num_epochs):\n",
    "    model.compile(loss = categorical_crossentropy, optimizer=Adam(), metrics=['acc'])\n",
    "    history= model.fit(x=X_train, y=y_train, batch_size=32, epochs=num_epochs, verbose=1,\n",
    "                       validation_split =0.2) \n",
    "\n",
    "    \n",
    "_ = compile_and_train(model2, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"정확도 : %.4f\" % (model2.evaluate(X_test, y_test)[1]))\n",
    "\n",
    "def evaluate_error(model):\n",
    "    pred = model.predict(X_test, batch_size=32)\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    pred = np.expand_dims(pred, axis=1) # make same shape as y_test\n",
    "    error = np.sum(np.not_equal(pred, y_test))/ y_test.shape[0]\n",
    "    return error\n",
    "\n",
    "\n",
    "\n",
    "evaluate_error(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(맨 앞부분에서 해보기)\n",
    "# generator -> 사진크기 늘리기 ( )\n",
    "# 정규화"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
