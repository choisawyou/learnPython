{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "%matplotlib inline  \n",
    "from matplotlib import font_manager,rc  #rc : resource configuration_자원에대하여 설정\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from matplotlib import font_manager,rc\n",
    "\n",
    "font_name = font_manager.FontProperties(fname='C:/Windows/Fonts/malgun.ttf').get_name()\n",
    "rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('team2.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,1:]\n",
    "y=df.iloc[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('team2.csv',index_col=0)\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "minmax_X = minmax_scale(X)\n",
    "minmax_y =  minmax_scale(y)\n",
    "df.iloc[:,1:]=minmax_X\n",
    "df.iloc[:,0]= minmax_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1=df.iloc[:,1:6]\n",
    "z2=df.iloc[:,6:11]\n",
    "z3=df.iloc[:,11:16]\n",
    "z4 =df.iloc[:,16:21]\n",
    "z5=df.iloc[:,21:26]\n",
    "z6=df.iloc[:,26:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z7=df.iloc[:,1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x26f025e6d48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=z7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x26f02939a08>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD4CAYAAAAaT9YAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAXD0lEQVR4nO3df3Rc5X3n8fdnsI0xNBgjGRIUcHeFy5qUbIu6p/lB8IbijUhS2oT0pC2NUkhNfHLsk5CyTlsIDbgbHKBNRZtmaWLQaVqnpPmxJeDUdlIRhzbpikKBUmorrZMVC63krll+KCBb3/5xr9D1MPKMrPmhR/N5naOjmXufe59nHs185tFz78xVRGBmZmkqtboBZmZ27BziZmYJc4ibmSXMIW5mljCHuJlZwhY1u8KOjo5YtWpVs6s1M0vWAw88MBYRnZXWNT3EV61axdDQULOrNTNLlqTvzbTO0ylmZglziJuZJcwhbmaWMIe4mVnC2i7Ex8bG2LhxIwcOHGh1U8zM5qztQnxgYICHH36YgYGBVjfFzGzOqoa4pE5JvyXpxrLlJ0naLumbkr4i6RWNa2Z9jI2NsWPHDiKCHTt2eDRuZsmr5TzxW4FhYFnZ8g8Bd0fEn0j6ALAB2Frn9tXVwMAAU1+9Ozk5ycDAAFdffXWLW1Uf/f39DA8Pz2qbkZERALq6uma1XXd3N5s2bZrVNs3kvpjmvpi2UPui6kg8It4DfLPCqjcDX8hvfxF43Uz7kLRe0pCkodHR0WNqaD3s2rWLiYkJACYmJti5c2fL2jIfjI+PMz4+3upmzAvui2nui2kp9IVquSiEpLXAWyLiI4VlfxURr89vLwZ2R8SF1fbV09MTrfrE5q233sq9997LxMQEixcv5q1vfeuCGYkfi6mRQn9/f4tb0nrui2nui2nzpS8kPRARPZXWzeXA5qSkqe1PAVo3xK5RX18fkgAolUr09fW1uEVmZnMzlxD/DnBpfvudwO65N6exOjo66O3tRRK9vb2ceuqprW6SmdmczDrEJW2VtAT4OLBe0iBwPnBHndvWEH19fZx33nkehZvZglDTtxhGxCAwmN/enC8eA3ob0qoG6ujo4Lbbbmt1M8zM6qLtPuxjZraQOMTNzBLmEDczS5hD3MwsYQ5xM7OEOcTNzBLmEDczS5hD3MwsYQ5xM7OEOcTNzBLmEDczS5hD3MwsYQ5xM7OEOcTNzBLmEDczS5hD3MwsYQ5xM7OEOcTNzBLmEDczS5hD3MwsYTVdKNnMWqu/v5/h4eGm1LVv3z4ANm3a1JT6uru7m1bXQuQQN0vA8PAwjz/0EKc3oa6pf88PPvRQw+t6quE1LHwOcbNEnA5ciVrdjLr6LNHqJiTPc+JmZglziJuZJcwhbmaWsLYL8bGxMTZu3MiBAwda3RQzszlruxAfGBjg4YcfZmBgoNVNMTObs7YK8bGxMXbs2EFEsGPHDo/GzSx5bRXiAwMDRGSnNE1OTno0bmbJa6sQ37VrFxMTEwBMTEywc+fOFrfIzGxuagpxSTdKuk/S/ZLOLSxfIukOSd+QdK+kkxvX1Lm7+OKLWbx4MQCLFy9m3bp1LW6RmdncVA1xSRcAp0XEhcBVwM2F1W8BnoiINwNfAt7XkFbWSV9fH1L2ibdSqURfX1+LW2RmNje1jMTXAdsBIuJRYEVh3TPAKfntDmC0rq2rs46ODnp7e5FEb28vp556aqubZGY2J7V8d8pKjgznQ5JKETEJfAu4TtJjwGHg9ZV2IGk9sB7gzDPPnFuL56ivr4/9+/d7FG5mC0ItI/GnmR5tA0zmAQ7wP4BbImIN8EvA7ZV2EBG3R0RPRPR0dnbOqcFz1dHRwW233eZRuJktCLWE+B7gMgBJa4CRwrqzmP42yX8FXl3X1pmZ2VHVMp1yD3CJpD1kc+BXSdoKXJf/fEpSCVgMXNOwllrb8YUQzKqrGuL51MmGssWb89//CFxU70aZQXYhhAf//kFY3oTK8gnCB594sPF1HWx8FdY+fFEIm9+Ww+TayerlElIabKvP2FmD+dlkZpYwh7iZWcLaLsT37t1Lb29v0w6YmZk1UtuF+JYtW3juuee44YYbWt0UM7M5a6sQ37t3L/v37wdg//79Ho2bWfLaKsS3bNlyxH2Pxs0sdW0V4lOj8Jnum5mlpq1CfNWqVUe9b2aWmrYK8WuvvfaI+x/96Edb1BIzs/poqxBfvXr1S6PvVatW0d3d3doGmZnNUVuFOGSj8RNPPNGjcDNbENruu1NWr17Njh07Wt0MM7O6aLuRuJnZQtJ2I3EzS5u/Z/5IDnEzS8rw8DB//8g/sHzZyobXNfmiAHjiuwcaXtfB5//1mLZziJtZcpYvW8l/PefdrW5GXf3l458/pu08J25mljCHuJlZwhziZmYJc4ibmSXMIW5mljCHuJlZwhziZmYJc4ibmSXMIW5mljCHuJlZwhziZmYJc4ibmSXMIW5mljCHuJlZwhziZmYJqynEJd0o6T5J90s6t2zdL0v6dr7uosY008zMKql6UQhJFwCnRcSFkl4D3Axckq87F7gAeH1ETDa0pWZm9jK1jMTXAdsBIuJRYEVh3ZXA94BvSLpLUkelHUhaL2lI0tDo6Ohc22xmZrlaQnwlUEzeQ5KmtjsbGIuItcAXgOsr7SAibo+Inojo6ezsnEt7zcysoJYQfxo4pXB/sjB1cgi4N7/9VWBNHdtmZmZV1HKh5D3AZcAeSWuAkcK6vyabH/99YC3wcL0b2G6uuOIKnnzyyabUNT4+DkBvb29T6nvlK1/Jtm3bmlKXWbuoJcTvAS6RtAd4BrhK0lbgOuBTwB2S3kU2Yr+iYS1tEwcPHmT8uWc5/rhoeF2lEACTP3im4XW9cFgcPHiw4fWYtZuqIZ5PnWwoW7w5//0i8K56N6qddXV10XHoSa7tebbVTamrLUMnsbSrq9XNMFtw/GEfM7OEOcTNzBLmEDczS5hD3MwsYQ5xM7OEOcTNzBLmEDczS5hD3MwsYQ5xM7OEOcTNzBLmEDczS5hD3MwsYQ5xM7OE1fJVtGYtMTIyAk9DaXCBjTUOwkiMVC9nVoMF9uowM2svHonbvNXV1cWoRplcO1m9cEJKgyW6zvB3q1t9eCRuZpYwh7iZWcIc4mZmCXOIm5klzCFuZpYwh7iZWcIc4mZmCXOIm5klzCFuZpawpD+x2d/fz/Dw8Ky2GRnJvrOiq2t2n5jr7u5m06ZNs9rGzKzRkg7xYzE+Pt7qJpiZ1U3SIX4sI+Opbfr7++vdHDOzpvOcuJlZwhziZmYJc4ibmSWsphCXdKOk+yTdL+ncCutPk/S8pKX1b6KZmc2kaohLugA4LSIuBK4Cbq5Q7CPAWJ3bZmZmVdQyEl8HbAeIiEeBFcWVkn4cCOCf6t46MzM7qlpCfCUwWrh/SFIJQNIy4CbgY0fbgaT1koYkDY2Ojh6tqJmZzUItIf40cErh/mRETF308HeArRHx9NF2EBG3R0RPRPR0dnYeY1PNzKxcLSG+B7gMQNIaYCS/vRI4H/gVSZ8H1gB3NqaZZmZWSS2f2LwHuETSHuAZ4CpJW4HrIqJnqpCkQeC9jWikmZlVVjXE86mTDWWLN1cot7ZObTIzsxr5wz5mZglziJuZJcwhbmaWMIe4mVnCHOJmZglziJuZJcwhbmaWMIe4mVnCHOJmZglziJuZJcwhbmaWMIe4mVnCHOJmZglziJuZJcwhbmaWsFouCtFw/f39DA8PN6Wuffv2AbBp06am1Nfd3d20usys/cyLEB8eHubBRx5jctmKhtelFwOAB777VMPrKj3/bw2vw8za27wIcYDJZSv4wZq3tboZdbX0sa+2uglmtsB5TtzMLGEOcTOzhM2b6RSb9v1nj2PL0EkNr+dfns/ew09bNtnwur7/7HGsbngtZu3HIT7PdHd3N62uF/MzdZauOrvhda2muY/NrF04xOeZZp6OOFVXf39/0+o0s/rynLiZWcIc4mZmCfN0is1vB6E02ISxxrP578YfT4aDwBlNqMfagkPc5q1mHgid+jqGs89o/EFezvBBXqsfh7jNWz7Ia1ad58TNzBLmEDczS5hD3MwsYQ5xM7OE1RTikm6UdJ+k+yWdW1h+nqSdkvZIukvSksY11czMylUNcUkXAKdFxIXAVcDNhdUBvD0iLgC+B1zakFaamVlFtYzE1wHbASLiUeCly+9ExCMR8UJ+9/8Bz1XagaT1koYkDY2Ojs6xyWZmNqWWEF8JFJP3kKQjtpP0BuBc4C8q7SAibo+Inojo6ezsPObGmpnZkWr5sM/TwCmF+5MRMQkgScBmYDHwnog4XP8mmpnZTGoZie8BLgOQtAYYKax7P/BkRNzoADcza75aQvweYImkPcAtwGZJW/MzUd4OXCVpMP+5upGNNTOzI1WdTsmnTjaULd6c/76k7i0yM7Oa+cM+ZmYJc4ibmSXMIW5mljCHuJlZwubFRSFGRkYoPXOAZUMDja9sMj8TsnRc4+s6fIiRkUONr8fM2ta8CPHly5czPj7elLqm6jlhaTO+q2sJy5cvb0I9Ztau5kWIb9u2rWl1+TJcZraQeE7czCxhDnEzs4Q5xM3MEuYQNzNLmEPczCxhDnEzs4Q5xM3MEuYQNzNLmEPczCxhDnEzs4Q5xM3MEuYQNzNLmEPczCxhDnEzs4Q5xM3MEuYQNzNLmEPczCxhDnEzs4Q5xM3MEuYQNzNLmEPczCxhDnEzs4Q5xM3MEuYQNzNLWE0hLulGSfdJul/SuYXlJ0naLumbkr4i6RWNa6qZmZWrGuKSLgBOi4gLgauAmwurPwTcHRFvAnYBGxrSSjMzq2hRDWXWAdsBIuJRSSsK694M3JTf/iLw6fo27+j6+/sZHh6e1Tb79u0DYNOmTbParru7e9bbNJP7YtpC7IuRkREOAFuIWW13CJhsSIterkRtgVL0IvDsyMisthkZGeHAMwf48t/2z2q7w5MTRMyu/46VJI4rLZ7VNocOv0iMjM+6rlr6fCUwWqxLUikiJoHjI2IiX34AOKXSDiStB9YDnHnmmbNuZD2dcMIJLa1/PnFfTJvvfbF8+XLGx2f/Aj/8wgtosjkxrlKJRccfP6ttFpE9ttk41r544YXDTDapL0qlEkuOn91b2hIWzbovAFTtnUnSJ8imTPbk97+ZT58g6VvAmyJiUtJK4FMRcdnR9tfT0xNDQ0OzbqiZWbuS9EBE9FRaV8uBzT3AZfmO1gDF/32+A1ya334nsHsO7TQzs1mqJcTvAZZI2gPcAmyWtFXSEuDjwHpJg8D5wB0Na6mZmb1M1UmbfO67/KyTzfnvMaC33o0yM7Pa+MM+ZmYJc4ibmSXMIW5mljCHuJlZwhziZmYJq/phn7pXKI0C32tqpS/XQXZmjbkvitwX09wX0+ZDX5wVEZ2VVjQ9xOcDSUMzffqp3bgvprkvprkvps33vvB0iplZwhziZmYJa9cQv73VDZhH3BfT3BfT3BfT5nVftOWcuJnZQrEgR+KSLpLUL+nXJS3Pl71W0i/WsO2l1crYwiHpJyRd3ep21IukMyT9lxrKvb3G/dX0epB0vqQr6rW/epF0tqRzqpTpkFTxzI+ycvOyL2Z7IY6WktQLfDi/ezYgYG9+/5MR8VVJ64B3AP8dOIfsqkS9ZBes+OHCvv4COA74z8BDwFMRcTmwEfhfM9S/HlgUEZ+q80OrG0mXRkTF9lfZrgP4APBasn59GPi9iBg96obZtucAkxGxt1rZVpF0HPBJ4D8Bi4HPRMQfAccDryiU+wpwUtnmrwVeVbgASstJ+jjwOqAbeAIYBz4ILAfWAn+TlxvMN/lR4BHgiYj4RbK/9d2F/X2S7LUAsAz4TkRspOz1IOlU4DNkfbQU+HRE/DHwQ8CrCuVm/fqaC0mfA04Hfgx4MF/8DrJvV10KPJ4P6P4n0xevuT4i/hp4C1kW3pnvK6m+SCrEgX3A7wIXkn3P+bNkVx56BPhuXubtwM0R8f+Bv5F0QNKXgZOBb0ztKCL+G4CknRGxrlrFkrqBt2Y3tTMiZnf9rwaRtDsifqqw6KUnRv7975XecM4BfjIi9heW/Qnw20xfQ/WNwOeBi2aqq3D/J8muBDZvQxy4AviniNiYB/oX8ouaHCEifqZ8maR7yB7fvBERvwYgaTvZxVimLtqytqzcWkknAP8QEWvL91Mo98Gp25J+FjhjhqLXkL0B3iNpETAo6WVBNNvX11zloTh10Zric7RY7KPAHRHxNUnLgIckPQF0kn3N9tS+kuqL1KZTfoSszR8jGyl+n+wPMwqszss8AkxdeegE4NXAzwE3lO8s7/gfO1qFkn5e0h8AVwKXA78EbJC0TdKVdXhMc7VkphUR8VhErC3/Ab5WofgPAbsi4vmIeB74OnBiY5rcEq8l+258IuIw2QVMzq1145iHB48k/QeyAPqwpKNd0HET8HVJv1K2/WAeUuUuIe+rCg4Ah/Pbk8DTwAsztK/q66sBzj7K1MhZwLcA8uf435JdzOamGcpDAn2RzEhc0sVk73wAHwJOI/u3/wOFMi+Q/Xtzg6Q7yQLumoiYKHtHnnIx8KKkN0fE1Ci9JOnPgN0R8Wmyf0u/HBE/KGz34fydvKtuD/AY5E+M8yUtiojZjBQX8/KR5SeAL0kaIevXrnxZeZ1bCndTGgQ8QHbR773KngxvIptyq+Wir4erF2kuST3AbwDvJnuD+pKka8rKlMj+MzsuIq6UdL2kj5EPaCqNzCX9OHBCRPxzvqiUTzH9VUR8gmxK6lclvYFsCuH6Ob6+6kbS+WQh+rNUPqPkc8BvSLoFeA3ZlOxdZNMwt5QXTqYvIiKpH7J57e6ynx8uK1Mie+IWl6m4LC/zNbIXwE6yuW7yDp0qcxHZiO1oP+ta2Bc/DTwGvKOw7Btk0yDr8/uvIpvbhuzNCODPgRUz7HM5cPIM63aTTcVM/ezOl78XuLzVz40qfVUie1P6Yv74L8uXvxH4TbIX2WDhZ5jsv73isre0+nEUHs/PAycW7r8SWEE22rsiX7YCeFfZdq/Jf3+6wj7Pyl8LKwrLdh9j+6q+vhrQJ3fl9Q0Cr8iXvRt4b6HMTwAfAd5DdqF3yI6ZvS3VvkhmJF5wKdm7XtEvAOcV7v9cXubOwrI3kB3wmRpJbgXuioi/k/RZ4DOS3lfcaUR8nWxaAQBJl5P9AYr7bYn83+cNZKPLO/P5tmfJDjC+u1C0xHR/nVD4fTDfz8VkIzrInmR/ly9/6TZwU0R8DSAiHi+0od4Pq2Eiu5j3VmA8sn+ly9fvAnZN3Zf0QeDxqcc930TEdkkfl/S6CqvvzMv8G9nc/1lkz/uVZMd0xsme/y+R9A7g/cAH8u1mJOmdwNLIDuJNLXsdcEFkI1So4fVVT5J+DRjK6/tV4LMzTHe+jeyYGsAVhefwS1MqqfVFiiG+lpefPXByhXLX5KFbLDN1wO90sqP02wAi4k8lPU82zTDv5dMofwjcFhEjkq4F/kw1nEKZe1tkl907IryKBy4rHDCdqvuy4t25PI4W2EA2Jzo4tSAivpUvS07kBzeL8gOba8sWbwM+GBGP5GU6gbvzf+2fzwcEZwM/U+kNroLFwK9L+uXCspa9viSdnFWThWZEDEm6lew4zxEi4voK219ONqVCin2RYogvrRQuFdxcHDFLeiP5kzsiniKbz3pJRNydl6tbQxuoC7gnIu4FiIhvS7qOwjx3YYR9PLBK2alm5+W/px7nTZEdqT+dbAqmeEoakv5PRLy6UO8W8id77rfq/sisEY4HnincnwqnRQCRnTq5tXyjKubN6ysinqbs4GREfPtY6kuxL1IM8TXFoCl4Xxx52t+MI/E5+Bey8z1bKrJTA/eXLfvfMP3EKJ8eqLK/p3j56A1Ju8vKDc6+tfPOJyUdLFv2UBROK0vcM8D/LVv2fuD387O1guw/qI9FdhrusWrE6ytVLe0Lf+x+gZlpGqSR+5L0XuBQRHyuHvXOB5JOAiYiouIpY2bzhUPcZiTpP0bEd6uXNLNWcYibmSUspQ9rmJlZGYe4mVnCHOJmZglziJuZJcwhbmaWsH8HY3RD0daXVn4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=z1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=z4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=z5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().iloc[:,0]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,1:]\n",
    "y=df.iloc[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000    1.000000\n",
       "2001    0.744132\n",
       "2002    0.542952\n",
       "2003    0.536967\n",
       "2004    0.479259\n",
       "2005    0.357155\n",
       "2006    0.398820\n",
       "2007    0.542668\n",
       "2008    0.443934\n",
       "2009    0.376762\n",
       "2010    0.457594\n",
       "2011    0.461086\n",
       "2012    0.503494\n",
       "2013    0.349967\n",
       "2014    0.346711\n",
       "2015    0.356239\n",
       "2016    0.253525\n",
       "2017    0.098794\n",
       "2018    0.000000\n",
       "Name: 출생아수, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,1:]\n",
    "y=df.iloc[:,0]\n",
    "\n",
    "\n",
    "df = pd.read_csv('team2.csv',index_col=0)\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "minmax_X = minmax_scale(X)\n",
    "minmax_y =  minmax_scale(y)\n",
    "df.iloc[:,1:]=minmax_X\n",
    "df.iloc[:,0]= minmax_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>출생아수</th>\n",
       "      <th>졸업자수</th>\n",
       "      <th>사교육비</th>\n",
       "      <th>인구</th>\n",
       "      <th>직장가입자</th>\n",
       "      <th>지역가입자</th>\n",
       "      <th>사회단체참여율</th>\n",
       "      <th>수출</th>\n",
       "      <th>수입</th>\n",
       "      <th>실질국내총생산(GDP)</th>\n",
       "      <th>...</th>\n",
       "      <th>노년부양비</th>\n",
       "      <th>노령화지수</th>\n",
       "      <th>사망자수</th>\n",
       "      <th>실업률</th>\n",
       "      <th>1인가구 비율</th>\n",
       "      <th>혼인건수(건)</th>\n",
       "      <th>주택매매가격동향</th>\n",
       "      <th>\\t맞벌이가구비율</th>\n",
       "      <th>유치원수</th>\n",
       "      <th>어린이집수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148319</td>\n",
       "      <td>0.581700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>0.048036</td>\n",
       "      <td>0.049183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.958259</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2001</td>\n",
       "      <td>0.744132</td>\n",
       "      <td>0.148319</td>\n",
       "      <td>0.581700</td>\n",
       "      <td>0.078732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>0.024485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.958259</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.033518</td>\n",
       "      <td>0.205619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2002</td>\n",
       "      <td>0.542952</td>\n",
       "      <td>0.148319</td>\n",
       "      <td>0.581700</td>\n",
       "      <td>0.138441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>0.026476</td>\n",
       "      <td>0.027983</td>\n",
       "      <td>0.085068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094737</td>\n",
       "      <td>0.055412</td>\n",
       "      <td>0.067464</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.958259</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117212</td>\n",
       "      <td>0.123883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2003</td>\n",
       "      <td>0.536967</td>\n",
       "      <td>0.148319</td>\n",
       "      <td>0.581700</td>\n",
       "      <td>0.192283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>0.095458</td>\n",
       "      <td>0.095733</td>\n",
       "      <td>0.122403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147368</td>\n",
       "      <td>0.087629</td>\n",
       "      <td>0.048176</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.958259</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198661</td>\n",
       "      <td>0.058748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004</td>\n",
       "      <td>0.479259</td>\n",
       "      <td>0.148319</td>\n",
       "      <td>0.581700</td>\n",
       "      <td>0.233642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227555</td>\n",
       "      <td>0.211530</td>\n",
       "      <td>0.185998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.122423</td>\n",
       "      <td>0.043758</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.958259</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.311382</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2005</td>\n",
       "      <td>0.357155</td>\n",
       "      <td>0.148319</td>\n",
       "      <td>0.581700</td>\n",
       "      <td>0.255832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294836</td>\n",
       "      <td>0.304844</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252632</td>\n",
       "      <td>0.161082</td>\n",
       "      <td>0.037468</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.328467</td>\n",
       "      <td>0.958259</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.371152</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006</td>\n",
       "      <td>0.398820</td>\n",
       "      <td>0.148319</td>\n",
       "      <td>0.581700</td>\n",
       "      <td>0.311009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385162</td>\n",
       "      <td>0.427005</td>\n",
       "      <td>0.312137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305263</td>\n",
       "      <td>0.207474</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.328467</td>\n",
       "      <td>0.958259</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.406508</td>\n",
       "      <td>0.056194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2007</td>\n",
       "      <td>0.542668</td>\n",
       "      <td>0.148319</td>\n",
       "      <td>0.581700</td>\n",
       "      <td>0.364362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.486444</td>\n",
       "      <td>0.547438</td>\n",
       "      <td>0.394104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357895</td>\n",
       "      <td>0.261598</td>\n",
       "      <td>0.048521</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.328467</td>\n",
       "      <td>0.958259</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.472769</td>\n",
       "      <td>0.061303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008</td>\n",
       "      <td>0.443934</td>\n",
       "      <td>0.148319</td>\n",
       "      <td>0.811041</td>\n",
       "      <td>0.445055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.597614</td>\n",
       "      <td>0.746444</td>\n",
       "      <td>0.439157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410526</td>\n",
       "      <td>0.315722</td>\n",
       "      <td>0.041813</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.328467</td>\n",
       "      <td>0.958259</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.580673</td>\n",
       "      <td>0.125160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2009</td>\n",
       "      <td>0.376762</td>\n",
       "      <td>0.148319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.468937</td>\n",
       "      <td>0.461773</td>\n",
       "      <td>0.451367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.368557</td>\n",
       "      <td>0.056884</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.328467</td>\n",
       "      <td>0.958259</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>0.162197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010</td>\n",
       "      <td>0.457594</td>\n",
       "      <td>0.148319</td>\n",
       "      <td>0.801097</td>\n",
       "      <td>0.553656</td>\n",
       "      <td>0.122116</td>\n",
       "      <td>0.116159</td>\n",
       "      <td>0.690265</td>\n",
       "      <td>0.695269</td>\n",
       "      <td>0.720911</td>\n",
       "      <td>0.557015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494737</td>\n",
       "      <td>0.423969</td>\n",
       "      <td>0.210737</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.613139</td>\n",
       "      <td>0.958259</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.765289</td>\n",
       "      <td>0.181354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2011</td>\n",
       "      <td>0.461086</td>\n",
       "      <td>0.148319</td>\n",
       "      <td>0.604542</td>\n",
       "      <td>0.636841</td>\n",
       "      <td>0.463630</td>\n",
       "      <td>0.504818</td>\n",
       "      <td>0.690265</td>\n",
       "      <td>0.890749</td>\n",
       "      <td>0.972623</td>\n",
       "      <td>0.618131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515789</td>\n",
       "      <td>0.472938</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.613139</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.839634</td>\n",
       "      <td>0.227331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2012</td>\n",
       "      <td>0.503494</td>\n",
       "      <td>0.437600</td>\n",
       "      <td>0.317807</td>\n",
       "      <td>0.694080</td>\n",
       "      <td>0.784315</td>\n",
       "      <td>0.855314</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.874588</td>\n",
       "      <td>0.960371</td>\n",
       "      <td>0.659438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.538660</td>\n",
       "      <td>0.425546</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.613139</td>\n",
       "      <td>0.971818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.949253</td>\n",
       "      <td>0.372925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013</td>\n",
       "      <td>0.349967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200828</td>\n",
       "      <td>0.743887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900473</td>\n",
       "      <td>0.950224</td>\n",
       "      <td>0.715157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652632</td>\n",
       "      <td>0.608247</td>\n",
       "      <td>0.408021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.613139</td>\n",
       "      <td>0.912125</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.551724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014</td>\n",
       "      <td>0.346711</td>\n",
       "      <td>0.081869</td>\n",
       "      <td>0.104212</td>\n",
       "      <td>0.812989</td>\n",
       "      <td>0.993477</td>\n",
       "      <td>0.914382</td>\n",
       "      <td>0.893805</td>\n",
       "      <td>0.929151</td>\n",
       "      <td>0.975418</td>\n",
       "      <td>0.773324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705263</td>\n",
       "      <td>0.679124</td>\n",
       "      <td>0.434108</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.613139</td>\n",
       "      <td>0.670048</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015</td>\n",
       "      <td>0.356239</td>\n",
       "      <td>0.817164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.871331</td>\n",
       "      <td>0.970920</td>\n",
       "      <td>0.831105</td>\n",
       "      <td>0.893805</td>\n",
       "      <td>0.828126</td>\n",
       "      <td>0.749550</td>\n",
       "      <td>0.825981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778947</td>\n",
       "      <td>0.756443</td>\n",
       "      <td>0.583235</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.868613</td>\n",
       "      <td>0.632561</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.948845</td>\n",
       "      <td>0.873563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016</td>\n",
       "      <td>0.253525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059610</td>\n",
       "      <td>0.915445</td>\n",
       "      <td>0.866544</td>\n",
       "      <td>0.699897</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>0.759180</td>\n",
       "      <td>0.672652</td>\n",
       "      <td>0.882773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831579</td>\n",
       "      <td>0.826031</td>\n",
       "      <td>0.672896</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.919708</td>\n",
       "      <td>0.336011</td>\n",
       "      <td>0.101449</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.890340</td>\n",
       "      <td>0.946360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017</td>\n",
       "      <td>0.098794</td>\n",
       "      <td>0.738348</td>\n",
       "      <td>0.220426</td>\n",
       "      <td>0.946782</td>\n",
       "      <td>0.866544</td>\n",
       "      <td>0.699897</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>0.931418</td>\n",
       "      <td>0.856068</td>\n",
       "      <td>0.945458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.912371</td>\n",
       "      <td>0.758467</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.095613</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.855801</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.738348</td>\n",
       "      <td>0.435365</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866544</td>\n",
       "      <td>0.699897</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.812240</td>\n",
       "      <td>0.989783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          출생아수      졸업자수      사교육비        인구     직장가입자     지역가입자   사회단체참여율  \\\n",
       "2000  1.000000  0.148319  0.581700  0.000000  0.000000  0.000000  0.530973   \n",
       "2001  0.744132  0.148319  0.581700  0.078732  0.000000  0.000000  0.530973   \n",
       "2002  0.542952  0.148319  0.581700  0.138441  0.000000  0.000000  0.530973   \n",
       "2003  0.536967  0.148319  0.581700  0.192283  0.000000  0.000000  0.530973   \n",
       "2004  0.479259  0.148319  0.581700  0.233642  0.000000  0.000000  0.000000   \n",
       "2005  0.357155  0.148319  0.581700  0.255832  0.000000  0.000000  0.000000   \n",
       "2006  0.398820  0.148319  0.581700  0.311009  0.000000  0.000000  0.000000   \n",
       "2007  0.542668  0.148319  0.581700  0.364362  0.000000  0.000000  0.088496   \n",
       "2008  0.443934  0.148319  0.811041  0.445055  0.000000  0.000000  0.088496   \n",
       "2009  0.376762  0.148319  1.000000  0.500101  0.000000  0.000000  0.088496   \n",
       "2010  0.457594  0.148319  0.801097  0.553656  0.122116  0.116159  0.690265   \n",
       "2011  0.461086  0.148319  0.604542  0.636841  0.463630  0.504818  0.690265   \n",
       "2012  0.503494  0.437600  0.317807  0.694080  0.784315  0.855314  1.000000   \n",
       "2013  0.349967  0.000000  0.200828  0.743887  1.000000  1.000000  1.000000   \n",
       "2014  0.346711  0.081869  0.104212  0.812989  0.993477  0.914382  0.893805   \n",
       "2015  0.356239  0.817164  0.000000  0.871331  0.970920  0.831105  0.893805   \n",
       "2016  0.253525  1.000000  0.059610  0.915445  0.866544  0.699897  0.964602   \n",
       "2017  0.098794  0.738348  0.220426  0.946782  0.866544  0.699897  0.964602   \n",
       "2018  0.000000  0.738348  0.435365  1.000000  0.866544  0.699897  0.964602   \n",
       "\n",
       "            수출        수입  실질국내총생산(GDP)  ...     노년부양비     노령화지수      사망자수  \\\n",
       "2000  0.048036  0.049183      0.000000  ...  0.000000  0.000000  0.089570   \n",
       "2001  0.000000  0.000000      0.000000  ...  0.042105  0.024485  0.000000   \n",
       "2002  0.026476  0.027983      0.085068  ...  0.094737  0.055412  0.067464   \n",
       "2003  0.095458  0.095733      0.122403  ...  0.147368  0.087629  0.048176   \n",
       "2004  0.227555  0.211530      0.185998  ...  0.200000  0.122423  0.043758   \n",
       "2005  0.294836  0.304844      0.241456  ...  0.252632  0.161082  0.037468   \n",
       "2006  0.385162  0.427005      0.312137  ...  0.305263  0.207474  0.006345   \n",
       "2007  0.486444  0.547438      0.394104  ...  0.357895  0.261598  0.048521   \n",
       "2008  0.597614  0.746444      0.439157  ...  0.410526  0.315722  0.041813   \n",
       "2009  0.468937  0.461773      0.451367  ...  0.452632  0.368557  0.056884   \n",
       "2010  0.695269  0.720911      0.557015  ...  0.494737  0.423969  0.210737   \n",
       "2011  0.890749  0.972623      0.618131  ...  0.515789  0.472938  0.246932   \n",
       "2012  0.874588  0.960371      0.659438  ...  0.578947  0.538660  0.425546   \n",
       "2013  0.900473  0.950224      0.715157  ...  0.652632  0.608247  0.408021   \n",
       "2014  0.929151  0.975418      0.773324  ...  0.705263  0.679124  0.434108   \n",
       "2015  0.828126  0.749550      0.825981  ...  0.778947  0.756443  0.583235   \n",
       "2016  0.759180  0.672652      0.882773  ...  0.831579  0.826031  0.672896   \n",
       "2017  0.931418  0.856068      0.945458  ...  0.915789  0.912371  0.758467   \n",
       "2018  1.000000  1.000000      1.000000  ...  1.000000  1.000000  1.000000   \n",
       "\n",
       "           실업률   1인가구 비율   혼인건수(건)  주택매매가격동향  \\t맞벌이가구비율      유치원수     어린이집수  \n",
       "2000  1.000000  0.000000  0.958259  0.275362   0.069767  0.000000  0.316731  \n",
       "2001  0.692308  0.000000  0.958259  0.275362   0.023256  0.033518  0.205619  \n",
       "2002  0.153846  0.000000  0.958259  0.275362   0.000000  0.117212  0.123883  \n",
       "2003  0.384615  0.000000  0.958259  0.275362   0.000000  0.198661  0.058748  \n",
       "2004  0.461538  0.000000  0.958259  0.275362   0.046512  0.311382  0.000000  \n",
       "2005  0.461538  0.328467  0.958259  0.275362   0.139535  0.371152  0.037037  \n",
       "2006  0.307692  0.328467  0.958259  0.275362   0.139535  0.406508  0.056194  \n",
       "2007  0.076923  0.328467  0.958259  0.275362   0.232558  0.472769  0.061303  \n",
       "2008  0.076923  0.328467  0.958259  0.275362   0.279070  0.580673  0.125160  \n",
       "2009  0.384615  0.328467  0.958259  0.275362   0.232558  0.664408  0.162197  \n",
       "2010  0.461538  0.613139  0.958259  0.275362   0.372093  0.765289  0.181354  \n",
       "2011  0.230769  0.613139  1.000000  1.000000   0.604651  0.839634  0.227331  \n",
       "2012  0.076923  0.613139  0.971818  0.000000   0.465116  0.949253  0.372925  \n",
       "2013  0.000000  0.613139  0.912125  0.043478   0.302326  1.000000  0.551724  \n",
       "2014  0.307692  0.613139  0.670048  0.246377   0.511628  0.998857  0.740741  \n",
       "2015  0.384615  0.868613  0.632561  0.507246   0.488372  0.948845  0.873563  \n",
       "2016  0.461538  0.919708  0.336011  0.101449   0.813953  0.890340  0.946360  \n",
       "2017  0.461538  0.963504  0.095613  0.217391   0.604651  0.855801  1.000000  \n",
       "2018  0.538462  1.000000  0.000000  0.159420   1.000000  0.812240  0.989783  \n",
       "\n",
       "[19 rows x 32 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICT01_22\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor #분류 데이터 \n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변수 중요도 rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.28, '유소년부양비'), (0.09, '노령화지수'), (0.09, '고등교육이수율'), (0.07, '어린이집수'), (0.07, '수출'), (0.06, '직장가입자'), (0.05, '실질국내총생산(GDP)'), (0.05, '사망자수'), (0.05, '문화여가지출률'), (0.04, '원자료'), (0.03, '혼인건수(건)'), (0.03, '인구'), (0.02, '졸업자수'), (0.02, '노년부양비'), (0.02, 'TV (%)'), (0.01, '실업률'), (0.01, '사교육비'), (0.01, '라디오 (%)'), (0.0, '지역가입자'), (0.0, '지니계수'), (0.0, '주택매매가격동향'), (0.0, '전국 이혼건수 '), (0.0, '유치원수'), (0.0, '신문 (%)'), (0.0, '수입'), (0.0, '사회단체참여율'), (0.0, '다문화출생아수'), (0.0, 'e러닝시장규모'), (0.0, '1인당주거면적'), (0.0, '1인가구 비율'), (0.0, '\\t맞벌이가구비율')]\n"
     ]
    }
   ],
   "source": [
    "X=df.iloc[:,1:]\n",
    "y=df.iloc[:,0]\n",
    "name = df.columns[1:]\n",
    "\n",
    "print(sorted(zip(map(lambda x: round(x,2),\n",
    "                    rf.feature_importances_),name),reverse = True)) #내림차순 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection / RFE   32 => 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 11,  1,  6,  8,  1, 16, 13,  1,  1,  1,  1,  3,  1, 12, 15,  1,\n",
       "        4,  5,  1,  2,  1,  1,  7,  1,  1,  1,  9, 14,  1,  1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature selection\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import RFE  # recursive feature elimination (재귀적 특징제거 )\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "estimator = SVR(kernel = 'linear') #svc로 만든ㄹ었지만 선형과 같다  #Regression 예측  SVC : Classification\n",
    "selector =RFE(estimator,16,step=1) #5개 변수만 남기겠다_ step : 한번에 하나씩 제거 ,5개를 없에야 하는 상황\n",
    "#변수를 제거하는 이유 : 잡음제거 _s 영향력이 없는 변수들 \n",
    "selector = selector.fit(X,y)\n",
    "selector.support_\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = sorted(zip(map(lambda x: x==1,\n",
    "                    selector.ranking_),name),reverse = True) #내림차순 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(ddd,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd = ['직장가입자','지역가입자','지니계수','주택매매가격동향','졸업자수','유소년부양비',\n",
    "'수출','수입','사망자수','사교육비','라디오 (%)','다문화출생아수','e러닝시장규모','TV (%)','\\t맞벌이가구비율']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 17)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:24:11] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "RMSE:0.274165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICT01_22\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\ICT01_22\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 데이터 프레임은 ndarray + dic : 중복가능/순서보장\n",
    "\n",
    "X=df.iloc[:,1:]\n",
    "y=df.iloc[:,0]\n",
    "    \n",
    "    \n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data = X,label =y)  #xg 전용 매트릭스로 바꿔줘야함 #DMatrix 얘때문에 속도가 빠름  #label은 종속변수 \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2, random_state=42)\n",
    "\n",
    "#objective = 'reg:linear' 선형 회귀방식  # tree방식도 있음\n",
    "# learning_rate(학습률) :경사하강법에 의해 동작하는 애들이 등장 \n",
    "#max_depth 과적합 방지 \n",
    "xg_reg = xgb.XGBRegressor(objective = 'reg:linear',colsample_bytree =0.3,  #col sample이 몇갠지\n",
    "                         learning_rate =0.1, max_depth = 5,alpha =10,n_estimators =10)\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "preds=xg_reg.predict(X_test)# ybar(예측치)가 결정됨\n",
    "rmse = np.sqrt(mean_squared_error(y_test,preds)) #예측상관계수 (MSE-Mean Square Error)_  차들(실제-예측)의 제곱 에 루트 : rmse\n",
    "print('RMSE:%f'%(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.DataFrame({'y_data':y_test,'preds':preds})\n",
    "y_test\n",
    "# preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB 상관계수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   출생아수   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                    nan\n",
      "Method:                 Least Squares   F-statistic:                     0.000\n",
      "Date:                Wed, 22 Jan 2020   Prob (F-statistic):                nan\n",
      "Time:                        21:24:15   Log-Likelihood:                 471.26\n",
      "No. Observations:                  15   AIC:                            -912.5\n",
      "Df Residuals:                       0   BIC:                            -901.9\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "인구              -2.1640        inf         -0        nan         nan         nan\n",
      "사회단체참여율         -0.4299        inf         -0        nan         nan         nan\n",
      "실질국내총생산(GDP)     6.2525        inf          0        nan         nan         nan\n",
      "1인당주거면적         -0.6044        inf         -0        nan         nan         nan\n",
      "고등교육이수율          5.4992        inf          0        nan         nan         nan\n",
      "원자료              0.0777        inf          0        nan         nan         nan\n",
      "문화여가지출률          0.1754        inf          0        nan         nan         nan\n",
      "전국 이혼건수         -0.1272        inf         -0        nan         nan         nan\n",
      "신문 (%)          -0.7259        inf         -0        nan         nan         nan\n",
      "노년부양비          -15.2318        inf         -0        nan         nan         nan\n",
      "노령화지수            8.4997        inf          0        nan         nan         nan\n",
      "실업률             -0.1607        inf         -0        nan         nan         nan\n",
      "1인가구 비율         -0.5932        inf         -0        nan         nan         nan\n",
      "혼인건수(건)          2.1812        inf          0        nan         nan         nan\n",
      "유치원수            -2.8210        inf         -0        nan         nan         nan\n",
      "어린이집수            0.7792        inf          0        nan         nan         nan\n",
      "==============================================================================\n",
      "Omnibus:                        3.578   Durbin-Watson:                   1.882\n",
      "Prob(Omnibus):                  0.167   Jarque-Bera (JB):                1.280\n",
      "Skew:                          -0.194   Prob(JB):                        0.527\n",
      "Kurtosis:                       1.622   Cond. No.                     2.24e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The input rank is higher than the number of observations.\n",
      "[3] The condition number is large, 2.24e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICT01_22\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1450: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=15\n",
      "  \"anyway, n=%i\" % int(n))\n",
      "C:\\Users\\ICT01_22\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1648: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "C:\\Users\\ICT01_22\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1649: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  * (1 - self.rsquared))\n",
      "C:\\Users\\ICT01_22\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1665: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return self.ssr/self.df_resid\n",
      "C:\\Users\\ICT01_22\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1578: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "인구              -2.163978\n",
       "사회단체참여율         -0.429853\n",
       "실질국내총생산(GDP)     6.252506\n",
       "1인당주거면적         -0.604412\n",
       "고등교육이수율          5.499244\n",
       "원자료              0.077745\n",
       "문화여가지출률          0.175364\n",
       "전국 이혼건수         -0.127229\n",
       "신문 (%)          -0.725949\n",
       "노년부양비          -15.231772\n",
       "노령화지수            8.499688\n",
       "실업률             -0.160706\n",
       "1인가구 비율         -0.593180\n",
       "혼인건수(건)          2.181181\n",
       "유치원수            -2.821028\n",
       "어린이집수            0.779209\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "model = sm.OLS(y_train, X_train)  \n",
    "result = model.fit()\n",
    "print(result.summary())\n",
    "\n",
    "result.params  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVR()\n",
    "model.fit(X_train, y_train)\n",
    "# cross_val_score(model,X,y,scoring='recall_macro',cv=10)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN MSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(X_train)\n",
    "print(\"MSE\",mean_squared_error(y_train, X_pred))\n",
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST MSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "print(\"MSE\",mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(r2_score(y_test,y_pred))\n",
    "df1=pd.DataFrame({'y_data':y_test,'preds':y_pred})\n",
    "df1.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE 차이 -0.11007424  | 상관계수 -0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TRAIN MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(X_train)\n",
    "print(\"MSE\",mean_squared_error(y_train, X_pred))\n",
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "print(\"MSE\",mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(r2_score(y_test,y_pred))\n",
    "df1=pd.DataFrame({'y_data':y_test,'preds':y_pred})\n",
    "df1.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE 차이 -1.712921252 | 상관계수 0.26399"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(X_train)\n",
    "print(\"MSE\",mean_squared_error(y_train, X_pred))\n",
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE\",mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(r2_score(y_test,y_pred))\n",
    "df1=pd.DataFrame({'y_data':y_test,'preds':y_pred})\n",
    "df1.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE 차이 0.08359161691 | 상관계수 0.94051"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection  / RFE 16 => 11 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('team2.csv',index_col=0)\n",
    "\n",
    "X=df.iloc[:,1:]\n",
    "y=df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "minmax_X = minmax_scale(X)\n",
    "minmax_y =  minmax_scale(y)\n",
    "df.iloc[:,1:]=minmax_X\n",
    "df.iloc[:,0]= minmax_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE \n",
    "from sklearn.svm import SVR \n",
    "\n",
    "estimator =SVR(kernel='linear') #선형회귀Regression 예측 \n",
    "selector =RFE(estimator, 11, step=1) \n",
    "\n",
    "\n",
    "# RFE(): ( 기존의 추정기를 받고 , 변수추출갯수(제거후), step 지정 )\n",
    "selector = selector.fit(X, y)\n",
    "selector.support_\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "second = sorted(zip(map(lambda x: x==1,\n",
    "                    selector.ranking_),name),reverse = True) #내림차순 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  후순위 11개 \n",
    "dr=['혼인건수(건)','직장가입자','지역가입자','지니계수','주택매매가격동향','졸업자수','유소년부양비','원자료',\n",
    "    '어린이집수','실질국내총생산(GDP)','수출','수입','사망자수','사교육비','라디오 (%)','다문화출생아수',\n",
    "    '노령화지수','e러닝시장규모','TV (%)','\\t맞벌이가구비율']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfre =df.drop(dr,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 12)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfre.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 데이터 프레임은 ndarray + dic : 중복가능/순서보장\n",
    "\n",
    "X=dfre.iloc[:,1:]\n",
    "y=dfre.iloc[:,0]\n",
    "     \n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data = X,label =y)  #xg 전용 매트릭스로 바꿔줘야함 #DMatrix 얘때문에 속도가 빠름  #label은 종속변수 \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2, random_state=42)\n",
    "\n",
    "#objective = 'reg:linear' 선형 회귀방식  # tree방식도 있음\n",
    "# learning_rate(학습률) :경사하강법에 의해 동작하는 애들이 등장 \n",
    "#max_depth 과적합 방지 \n",
    "xg_reg = xgb.XGBRegressor(objective = 'reg:linear',colsample_bytree =0.3,  #col sample이 몇갠지\n",
    "                         learning_rate =0.1, max_depth = 5,alpha =10,n_estimators =10)\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "preds=xg_reg.predict(X_test)# ybar(예측치)가 결정됨\n",
    "rmse = np.sqrt(mean_squared_error(y_test,preds)) #예측상관계수 (MSE-Mean Square Error)_  차들(실제-예측)의 제곱 에 루트 : rmse\n",
    "print('RMSE:%f'%(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.DataFrame({'y_data':y_test,'preds':preds})\n",
    "y_test\n",
    "# preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE 0.281653 | 상관계수 0.705497"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVR()\n",
    "model.fit(X_train, y_train)\n",
    "# cross_val_score(model,X,y,scoring='recall_macro',cv=10)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(X_train)\n",
    "print(\"MSE\",mean_squared_error(y_train, X_pred))\n",
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST MSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "print(\"MSE\",mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(r2_score(y_test,y_pred))\n",
    "df1=pd.DataFrame({'y_data':y_test,'preds':y_pred})\n",
    "df1.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE 차이 0.109360| 상관계수 -0.267817"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   출생아수   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                    nan\n",
      "Method:                 Least Squares   F-statistic:                     0.000\n",
      "Date:                Wed, 22 Jan 2020   Prob (F-statistic):                nan\n",
      "Time:                        21:27:19   Log-Likelihood:                 170.43\n",
      "No. Observations:                  15   AIC:                            -310.9\n",
      "Df Residuals:                       0   BIC:                            -300.2\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "졸업자수           -14.3520        inf         -0        nan         nan         nan\n",
      "사교육비           -22.9489        inf         -0        nan         nan         nan\n",
      "인구              -0.2037        inf         -0        nan         nan         nan\n",
      "직장가입자           -0.0510        inf         -0        nan         nan         nan\n",
      "지역가입자            0.1365        inf          0        nan         nan         nan\n",
      "사회단체참여율          4.2367        inf          0        nan         nan         nan\n",
      "수출              -0.0019        inf         -0        nan         nan         nan\n",
      "수입               0.0005        inf          0        nan         nan         nan\n",
      "실질국내총생산(GDP)    -2.5268        inf         -0        nan         nan         nan\n",
      "1인당주거면적         92.2857        inf          0        nan         nan         nan\n",
      "고등교육이수율        -40.1127        inf         -0        nan         nan         nan\n",
      "원자료            640.4277        inf          0        nan         nan         nan\n",
      "e러닝시장규모          0.5154        inf          0        nan         nan         nan\n",
      "문화여가지출률         -7.7248        inf         -0        nan         nan         nan\n",
      "지니계수            -0.0152        inf         -0        nan         nan         nan\n",
      "다문화출생아수        -54.8196        inf         -0        nan         nan         nan\n",
      "전국 이혼건수          3.3808        inf          0        nan         nan         nan\n",
      "TV (%)          35.9850        inf          0        nan         nan         nan\n",
      "라디오 (%)         13.2493        inf          0        nan         nan         nan\n",
      "신문 (%)          29.5484        inf          0        nan         nan         nan\n",
      "유소년부양비           0.3183        inf          0        nan         nan         nan\n",
      "노년부양비          -12.6141        inf         -0        nan         nan         nan\n",
      "노령화지수          -13.8420        inf         -0        nan         nan         nan\n",
      "사망자수            28.7995        inf          0        nan         nan         nan\n",
      "실업률            -22.5593        inf         -0        nan         nan         nan\n",
      "1인가구 비율       -169.1864        inf         -0        nan         nan         nan\n",
      "혼인건수(건)          0.5386        inf          0        nan         nan         nan\n",
      "주택매매가격동향        42.9269        inf          0        nan         nan         nan\n",
      "\t맞벌이가구비율        -9.4867        inf         -0        nan         nan         nan\n",
      "유치원수           113.6979        inf          0        nan         nan         nan\n",
      "어린이집수         1866.0754        inf          0        nan         nan         nan\n",
      "==============================================================================\n",
      "Omnibus:                        6.134   Durbin-Watson:                   0.897\n",
      "Prob(Omnibus):                  0.047   Jarque-Bera (JB):                3.523\n",
      "Skew:                          -1.159   Prob(JB):                        0.172\n",
      "Kurtosis:                       3.518   Cond. No.                     1.48e+08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The input rank is higher than the number of observations.\n",
      "[3] The condition number is large, 1.48e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "졸업자수             -14.351976\n",
       "사교육비             -22.948903\n",
       "인구                -0.203691\n",
       "직장가입자             -0.051026\n",
       "지역가입자              0.136469\n",
       "사회단체참여율            4.236692\n",
       "수출                -0.001853\n",
       "수입                 0.000474\n",
       "실질국내총생산(GDP)      -2.526764\n",
       "1인당주거면적           92.285691\n",
       "고등교육이수율          -40.112732\n",
       "원자료              640.427666\n",
       "e러닝시장규모            0.515394\n",
       "문화여가지출률           -7.724823\n",
       "지니계수              -0.015250\n",
       "다문화출생아수          -54.819625\n",
       "전국 이혼건수            3.380787\n",
       "TV (%)            35.985039\n",
       "라디오 (%)           13.249251\n",
       "신문 (%)            29.548363\n",
       "유소년부양비             0.318252\n",
       "노년부양비            -12.614136\n",
       "노령화지수            -13.841972\n",
       "사망자수              28.799546\n",
       "실업률              -22.559279\n",
       "1인가구 비율         -169.186384\n",
       "혼인건수(건)            0.538623\n",
       "주택매매가격동향          42.926947\n",
       "\\t맞벌이가구비율         -9.486665\n",
       "유치원수             113.697934\n",
       "어린이집수           1866.075387\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "model = sm.OLS(y_train, X_train)  \n",
    "result = model.fit()\n",
    "print(result.summary())\n",
    "\n",
    "result.params  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Durbin-Watson: 1.670"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "print(\"MSE\",mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(r2_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련 mse\n",
    "X_pred = model.predict(X_train)\n",
    "print(\"MSE\",mean_squared_error(y_train, X_pred))\n",
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame({'y_data':y_test,'preds':y_pred})\n",
    "df1.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE차이 0.09914220292 | -0.75539"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE\",mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(r2_score(y_test,y_pred))\n",
    "df1=pd.DataFrame({'y_data':y_test,'preds':y_pred})\n",
    "df1.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(X_train)\n",
    "print(\"MSE\",mean_squared_error(y_train, X_pred))\n",
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE 차이 0.08497664988 | 0.803196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection 11 => 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('team2.csv',index_col=0)\n",
    "\n",
    "X = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]\n",
    "name = df.columns[1:]\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "minmax_X = minmax_scale(X)\n",
    "minmax_y =  minmax_scale(y)\n",
    "df.iloc[:,1:]=minmax_X\n",
    "df.iloc[:,0] = minmax_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE  # recursive feature elimination (재귀적 특징제거 )\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "estimator = SVR(kernel = 'linear') #svc로 만든ㄹ었지만 선형과 같다  #Regression 예측  SVC : Classification\n",
    "selector =RFE(estimator,5,step=1) #5개 변수만 남기겠다_ step : 한번에 하나씩 제거 ,5개를 없에야 하는 상황\n",
    "#변수를 제거하는 이유 : 잡음제거 _s 영향력이 없는 변수들 \n",
    "selector = selector.fit(X,y)\n",
    "selector.support_\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "405.788px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
